 warwick.ac.uk/lib-publications  Manuscript version: Author’s Accepted Manuscript  The version presented in WRAP is the author’s accepted manuscript and may differ from the  published version or Version of Record.    Persistent WRAP URL:  http://wrap.warwick.ac.uk/124656                               How to cite:  Please refer to published version for the most recent bibliographic citation information.   If a published version is known of, the repository item page linked to above, will contain  details on accessing it.    Copyright and reuse:  The Warwick Research Archive Portal (WRAP) makes this work by researchers of the  University of Warwick available open access under the following conditions.    © 2019 Elsevier. Licensed under the Creative Commons Attribution-NonCommercialNoDerivatives 4.0 International http://creativecommons.org/licenses/by-nc-nd/4.0/.  Publisher’s statement:  Please refer to the repository item page, publisher’s statement section, for further  information.    For more information, please contact the WRAP Team at: wrap@warwick.ac.uk. Journal Pre-proof Evaluating E-learning Systems Success: An Empirical Study Dimah Al-Fraihat, Mike Joy, Ra’ed Masa’deh, Jane Sinclair PII: S0747-5632(19)30291-2 DOI: https://doi.org/10.1016/j.chb.2019.08.004 Reference: CHB 6097 To appear in: Computers in Human Behavior Received Date: 27 March 2019 Accepted Date: 06 August 2019 Please cite this article as: Dimah Al-Fraihat, Mike Joy, Ra’ed Masa’deh, Jane Sinclair, Evaluating Elearning Systems Success: An Empirical Study,  Computers in Human Behavior (2019),  https://doi. org/10.1016/j.chb.2019.08.004 This is a PDF file of an article that has undergone enhancements after acceptance, such as the  addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive  version of record. This version will undergo additional copyediting, typesetting and review before it  is published in its final form, but we are providing this version to give early visibility of the article.  Please note that, during the production process, errors may be discovered which could affect the  content, and all legal disclaimers that apply to the journal pertain. © 2019 Published by Elsevier. Journal Pre-proof    Evaluating E-learning Systems Success: An Empirical Study Dimah Al-Fraihat* <d.al-fraihat@warwick.ac.uk>, Mike Joy < M.S.Joy@warwick.ac.uk>, Ra’ed  Masa’deh < Moh-d.Masa-deh@warwick.ac.uk> Jane Sinclair < J.E.Sinclair@warwick.ac.uk> Department of Computer Science, University of Warwick, United Kingdom * Corresponding author full postal address: Department of Computer Science, University of Warwick, Coventry, CV4 7AL Declarations of interest: none This research did not receive any specific grant from funding agencies in the public, commercial, or  not-for-profit sectors. Colour should be used for the figures in print. Journal Pre-proof    1 Evaluating E-learning Systems Success: An Empirical Study ABSTRACT E-learning, as a direct result of the integration of technology and education, has emerged as a powerful medium of learning  particularly using Internet technologies. The undeniable significance of e-learning in education has led to a massive growth in  the number of e-learning courses and systems offering different types of services. Thus, evaluation of e-learning -systems is vital  to ensure successful delivery, effective use, and positive impacts on learners. Based on an intensive review of the literature, a  comprehensive model has been developed which provides a holistic picture and identifies different levels of success related to a  broad range of success determinants. The model has been empirically validated by fitting the model to data collected from 563  students engaged with an e-learning system in one of the UK universities through a quantitative method of Partial Least Squares  Structural Equation Modelling (PLS-SEM). The determinants of e-learning perceived satisfaction are technical system quality,  information quality, service quality, support system quality, learner quality, instructor quality, and perceived usefulness, which  together explain 71.4% of the variance of perceived satisfaction. The drivers of perceived usefulness are technical system quality,  information quality, support system quality, learner quality, and instructor quality, and these explain 54.2% of the variance of  perceived usefulness. Four constructs were found to be the determinants of e-learning use, namely educational system quality,  support system quality, learner quality, and perceived usefulness, and together they account for 34.1%. Finally, 64.7% of the  variance of e-learning benefits was explained by perceived usefulness, perceived satisfaction, and use. Keywords E-learning, e-learning success, e-learning evaluation, DeLone and McLean information systems success model, TAM, e-learning  satisfaction. 1 Introduction  The development of Information Technology (IT) has motivated improvements in various fields such as finance, business, health,  and education. As a result, education has grown rapidly and stimulated the adoption of e-learning, which is a direct result of the  integration of education and technology and is deemed to be a powerful medium for learning (Al-Fraihat et al., 2017). E-learning  has become mainstream in the education sector and has been massively adopted in higher education. According to Dahlstorm et  al. (2014), 99% of institutions have Learning Management Systems (LMSs) in place, and 85% of them have been utilized, and  in the UK, 95% of higher education institutes have adopted LMSs to support their educational services (McGill and Klobas,  2009).  Accordingly, the quality of e-learning systems has received a considerable amount of research attention and a large number of  researchers have attempted to identify e-learning success factors to maximize the effectiveness of these systems (e.g., Wang,  2003; Wahab, 2008; Lee and Lee, 2008; Lee et al., 2009; Lee, 2010; Park, 2009; Ali and Ahmad, 2011; Islam, 2013; Fathema et  al., 2015; Mohammadi, 2015; Mtebe and Raphael, 2018). Broadly, the majority of these studies have examined individual parts  of key determinants of e-learning systems success ignoring the synergistic effects of the success variables interacting together  (Eom and Ashill, 2018). Another direction of research has dealt with the direct relationships between e-learning quality factors  and usage or satisfaction (e.g., Selim, 2003; Ozkan and Koseler, 2009).  The significant amount of research in e-learning has advanced our understanding of the pivotal success factors of e-learning,  such as system quality, information quality, service quality, satisfaction, and usefulness. However, the excessive number of  measurements among dependent and independent variables is the main challenge that researchers face toward developing an elearning success model.  Evidently, there is a need for a comprehensive success model for multiple levels of success (Eom and Ashill, 2018). Bearing in  mind that an e-learning system is an information system that integrates human entities (i.e., learners and instructors) and nonhuman entities (e.g., learning management systems), it is crucial to investigate multiple dimensions of success in relation to both  entities.  Cidral et al. (2018) classified studies in e-learning from 2001 till 2016. It was found that studies from 2001 started with a focus  on intention to use, adoption, usability, course contents and customization and evolved later to include satisfaction from 2007.  Recently, from 2013, studies have focused on “the overall success of e-learning and on how students’ characteristics affect elearning” (Cidral et al. 2018). In general, earlier studies have been concerned more about the technology itself. However, as the  technology becomes increasingly reliable and accessible, recent research has focused more on students’ and instructors’ attitudes  and interactions, which play a vital role in e-learning success (Cheng, 2011; Liaw et al., 2007; Selim, 2007). Further research is  needed to evaluate these systems for continuing improvement and meeting learners’ needs.  On account of the fact that e-learning success factors vary in terms of their relative significance based on the context, different  strategies have been adopted to deal with these factors. For example, in developing countries, obstacles are found in resources,  accessibility and infrastructure, as well as existence of communication features, and the important role of social factors (e.g.  learner and instructor) receive more attention. In contrast, in developed countries, enhancing lifelong education, quality of  information, usefulness of the systems, and ethical and legal considerations are more pronounced (Bhuasiri et al., 2012;  Mohammadi, 2015). Thus, this study aims to fill this void and address these problems by investigating the factors that influence  the success of e-learning, and proposing a model that incorporates the determinants and aspects for e-learning success that are  of recent concern and interest to e-learning users, and sharing practical experiences of e-learning success measurements in  developed countries such as, the UK. Journal Pre-proof    2 2 Theoretical Foundation E-learning has expanded rapidly with a variety of technologies and devices to access learning resources, such as laptops,  computers, smartphones, and tablets. Technology has profoundly impacted education and learning and teaching methods.  Traditionally, accessibility to learning materials has been restricted to few individuals. Collaboration and communication has  also been limited to students in the same classroom.  Today, a great number of learning resources in different formats (e.g., text,  images, audio, videos) are available through the Internet fostering self-paced learning and transcending geographical boundaries.  In addition, more opportunities for collaboration and interactive communication features have been expanded, such as wikis,  forums, chat and peer-to-peer activities.   Due to the continuous evolution of technology, there is no single consensual definition for e-learning. For example, Lee et al.  (2011) defined e-learning as “an information system that can integrate a wide variety of instructional material (via audio, video,  and text mediums) conveyed through e-mail, live chat sessions, online discussions, forums, quizzes, and assignments”. Other  researchers use the concept of e-learning to refer to the technology intervention in the learning process (e.g., Sun et al., 2008).   In this research, we adopt the definition that considers an e-learning system as an information systems. Thus, the success of an  e-learning system is viewed as an IS success.  Reviewing the literature revealed four categories for measuring the success of e-learning based on the DeLone and McLean  information systems success model; the Technology Acceptance Model (TAM); the User Satisfaction Models; and E-Learning  Quality Models (Al-Fraihat et al., 2018). More details about each approach is given as follows. 2.1 E-learning Success based on DeLone and Mclean Information Systems Success Model In the context of information systems, attempts to define the success of information systems were shallow and imprecise due to  the complexity and interdisciplinary nature of the discipline (Peter et al., 2008). To address this, DeLone and McLean (1992)  introduced a model to measure information systems success, after reviewing 180 research papers published during the period  1981-1987 for measuring the success of information systems. The model contains six variables: system quality, information  quality, use, user satisfaction, individual impact, and organizational impact. Indeed, the model is considered, more precisely, as a comprehensive framework or a taxonomy, as no empirical validation was  proposed by the researchers. DeLone and McLean (1992) called for further development and validation for their model.  Information systems researchers attempted to examine this model partially or completely (Seddon and Kiew, 1994; Taylor and  Todd, 1995; Jurison 1996; Igbaria and Tan, 1997). Seddon and Kiew (1994) were among the early researcher who partially tested  the model and supported some paths in the model. Other researchers (e.g., Pitt et al., 1995) incorporated ‘service quality’ to the  model.  Jurison (1996), in a longitudinal study, researched the nature of information systems benefits and argued that individual  impacts can be assessed first, but organizational impact needs a long period of time to be assessed. Seddon (1997) criticised their  model and considered the reciprocal relationship between use and user satisfaction very confusing. He respecified the model and  replaced ‘system use’ with ‘perceived usefulness’ and allowed only one direction of causality. Rai et al. (2002) subsequently  conducted an empirical study and compared the DeLone and McLean (1992) and Seddon (1997) models. Rai et al. extended  Seddon’s model and proposed a new model to include a correlational path between perceived usefulness and use. Ten years later,  DeLone and McLean updated their model. The new model introduced ‘service quality’ as a new construct to the model, the ‘use’  construct was split into ‘intention to use’ and ‘use’ to measure systems success in areas where the use of the system is voluntary  and mandatory, and two constructs (individual and organizational impacts) were merged into benefits. Researchers adopted this  model partially and totally to better understand the success of a variety of information systems including e-learning systems  (Chen, 2010; Cidral et al. 2018; Hassanzadeh et al., 2012; Lin, 2007; Lwoga, 2014; Marjanovic et al., 2015; Wang and Chiu,  2011). Surveying the literature reveals that there is a consensus about the validity of this model (or part of it) to evaluate the success of  e-learning systems. However, there is a contradiction in the results among the studies. For example, while some studies found a  significant effect of the overall quality aspects (system, information, and service quality) on actual system usage, other  researchers reported the insignificance of this relation. A study on actual use of the online learning system OLS (Lin, 2007)  found a significant effect of system quality, information quality, and service quality on the actual use through user satisfaction  and behavioural intention to use OLS. Another study by Eom et al. (2012) investigated the direct relationship between system  quality and information quality on system use and found it significant. In contrast, in the studies conducted in an Australian  university by Klobas and McGill (2010) and Cidral et al. (2018) in Brazilian universities, researchers reported the absence of  any significant relationship between quality aspects and use. The contradiction among studies in the literature could be due to  the mandatory or voluntary nature of using the system, according to Eom et al. (2012), which may be explained by the fact that,  in a mandatory context, students use the e-learning system regardless of its quality because it is the only place to access learning  resources, while in a voluntary context, the quality aspects of the system influence the users’ decision to use the system or not.  Another reason might be due to other intervening variables not explained by the model. Also, results could be dependent on both  the context of the study and sample differences. There are also differences between the variance explained (R2) by quality factors  among the dependent variables in these models. For that reason, Eom et al. (2012) stated that “the DeLone and McLean model  has limited explanatory power for explaining the role of e-learning systems on the outcomes of e-learning”. Researchers have  called for further research to investigate e-learning quality factors to increase the explanatory power of the DeLone and McLean  model (Eom et al., 2012; Eom, 2015; Awang et al., 2018). 2.2 E-learning Success based on Technology Acceptance Model The technology acceptance model (TAM) by Davis (1989) was the second direction for evaluating the success of information  systems. It has been the most widely used theory to measure the success of new technology in terms of the acceptance and use  of technology (Surendran, 2012). This model was established based on the Theory of Reasoned Action (TRA) and classified  under the theories of Social Psychology. The model suggests that when users are presented with new technology, a number of Journal Pre-proof    3 factors influence their decision about how and when they will use it (Davis, 1989). Based on this model, external factors, social  factors (e.g., skills and language), cultural factors, and political factors (i.e., the impact of using the technology in politics), are  the determinants of perceived usefulness and perceived ease of use (Surendran, 2012).  In turn, perceived usefulness and  perceived ease of use are the major determinants of attitude toward using the technology and intention to use. Successively,  behavioral intention to use is the main determinant of actual system usage.   A large number of studies have been conducted based on empirically testing the robustness and validity of this model, and its  instrument and measurement scales. The model has been widely extended using different variables, and has also been  successfully used to explain usefulness and usage in different contexts, including the context of e-learning. An important  extension, TAM2, to the original TAM was introduced by Venkatesh and Davis (2000), which expanded the original model by  adding subjective norm, voluntariness, experience, and image (social influence processes). Also job relevance, output quality,  and result demonstrability were added (cognitive instrumental processes). Empirical research showed that TAM2 better  explained user acceptance. Three years later, Venkatesh et al. (2003) constructed the Unified Theory of Acceptance and Use of  Technology (UTAUT). The introduction of UTAUT has significantly enhanced the explanation power of the variance in usage  intention and has been extensively used by researchers. Extensions to TAM have been evolving over time, and in 2008 a new  model was released named TAM3 by Venkatesh and Bala (2008), followed by UTAUT2 in 2012 (Venkatesh et al., 2012).  TAM in its different versions: TAM, TAM2, TAM3, UTATUT, and UTAUT2 have received considerable attention from  researchers in different fields and have been empirically examined. Studies carried out with TAM in the context of e-learning  systems, similarly, have used the model to predict usefulness, intention to use and usage of e-learning systems. Researchers have  extended the model by adding external variables to understand the determinants of e-learning systems’ acceptance and usage.  The external variables have assisted researchers in understanding why a particular system may not be adopted, thus appropriate  ‘corrective steps’ can be taken (Davis et al., 1989). Based on the literature study conducted by Abdullah and Ward (2016), the  five most used external factors by researchers and confirmed to have a relationship with TAM in the context of e-learning are  self-efficacy, subjective norm, enjoyment, computer anxiety, and prior experience. According to the review study conducted by Sumak et al. (2011), TAM is the most popular theory adopted in e-learning  acceptance research with 86% of studies utilizing this model as a ground theory. Though acceptance and use are necessary to  measure success, they are not the same as success (Peter et al., 2008). The model has been widely criticised despite its frequent  use. Chuttur (2009) noted that “Researchers share mixed opinions regarding its theoretical assumptions and practical  effectiveness” and Legris et al. (2003) concluded “TAM is a useful model but has to be integrated into a broader one which  would include variables related to both human and social change processes. Also, researchers criticised the poor fit of this model,  limited explanatory and predictive power, and lack of practical value (Legris et al., 2003). To illustrate, both TAM and TAM2  explained about 40% of system use (Legris et al., 2003) while researchers extended TAM and provided better explanatory power  models with total variance explained ranging from 52%-70% (Abdullah and Ward, 2016). Furthermore, researchers claimed that  the several attempts to expand this model led to “theoretical chaos and confusion” (Benbasat and Barki, 2007). 2.3 E-learning Success based on User Satisfaction Models Another significant direction of information systems research is the user satisfaction approach. Satisfaction has been found a  fundamental measure in the success, effectiveness, usage, and acceptance of information systems (Bailey and Peasons, 1983;  DeLone and  McLean, 1992; Doll and Tokzadeh, 1988; Harter and Hert, 1997; Ives et al., 1983; Seddon, 1997; Thong and  Yap,  1996). There is a wide agreement that satisfaction is an attitude held by individual users (Thong and Yap, 1996). Remenyi and  Money (1991) defined user satisfaction as a measure of the discrepancy between a user’s expectations about a specific  information systems compared to the perceived performance of the system. Cyert and March (1963) are believed to be the first  researchers to introduce the concept of user satisfaction to assess information systems success, and suggested that if an  information systems meets users’ needs, their satisfaction will increase. Similarly, Evans (1976 cited in Thong and Yap, 1996)  stated that a lower satisfaction level about the information systems will hinder system usage. Seddon and Kiew (1994) concluded  in her study that user satisfaction is the most general and important measure of information systems success. The same results  were achieved by Igbaria and Tan (1997). The first empirical attempt to identify user satisfaction as a measure in information systems success was by Bailey and Pearson  (1983), where they developed an instrument with 39 factors for measuring computer user satisfaction. A shorter condensed  instrument, with 13 factors, was produced by Ives et al. (1983). Goodhue (1986) criticised Ives et al.’s (1983) instrument and  considered it lacking strong theoretical support. Later, Baroudi and Orlikowski (1988) empirically validated their short  instrument. The contribution of user satisfaction studies continued, and a highly rated reliable questionnaire to measure user  satisfaction was proposed by Chin et al. (1988). In 1992, DeLone and McLean (1992) employed satisfaction as a single construct  in their model due to its high degree of reliability and validity compared with other measures. Further, Doll et al. (2004) provided  a 12-item valid scale for end-user computing satisfaction (EUCS).  Different approaches have been used to measure user satisfaction. One direction is based on assessing the level of satisfaction of  a specific instance of information systems, i.e., at micro level (Ilias et al., 2009; Ong and Lai, 2007) or with all computer  technologies available in the organization, i.e. at macro level (Landrum et al., 2010; Wixom and Todd, 2005). The other direction  is based on assessing the success of information systems based on satisfaction as a single comprehensive construct (Somers et  al. 2003; Doll et al., 2004; Leclercq, 2007; Wang and Liao, 2007), or to incorporate it in the model as a construct together with  other constructs (DeLone and McLean, 1992; Kang and Lee, 2010).  User satisfaction in assessing e-learning systems success has also been utilized as a single comprehensive factor or alongside  other factors. For example, the model of Sun et al. (2008) considered the six dimensions – learners, instructors, course,  technology, design, and environment – as being the critical dimensions affecting learner satisfaction. Thirteen factors under these  six dimensions were hypothesised and among these, computer anxiety, instructor attitude toward e-learning, course quality, Journal Pre-proof    4 flexibility, perceived usefulness, perceived ease of use, and diversity in assessment, gained empirical support. The results of the  study showed that improving users’ satisfaction, through these factors, drives a successful e-learning system. Another important  contribution to e-learning success evaluation was the model proposed by Ozkan and Koseler (2009). The researchers constructed  a hexagonal model based on quality factors (system quality, information quality, and service quality) and social issues (supportive  factors, learner perspective, and instructor attitudes). The relationships between the six dimensions and e-learning satisfaction  were found significant and accounted for 76.9% of the variance of e-learning satisfaction. Researchers concluded that this model  should be perceived as basics for assessing the effectiveness of e-learning and recommended extending the model with other  dimensions. Another study of blended e-learning system environments undertaken by Wu et al. (2010) introduced an e-learning  satisfaction model BELS which was tested with 212 participants. The findings of the study indicated that computer self-efficacy,  performance expectations, system functionality, content feature, interaction, and learning climate, are the primary determinants  of student learning satisfaction. All relationships were found significant. The model explained 67.8% of the variance of learning  satisfaction with BELS. 2.4 E-learning Success based on E-Learning Quality Models The fourth direction of research in evaluating e-learning systems is to assess the overall quality of e-learning. Though quality is  a general term, different approaches and models have emerged, and different aspects of and approaches to quality have been  considered in e-learning quality models (e.g., excellence models, e-learning quality surveys, ISO 9000, benchmarking).  An important model proposed by MacDonald et al. (2001) was the Demand-Driven Learning Model (DDLM) to evaluate webbased learning (WBL) systems. The model was developed in response to the need to design new learning models to meet users’  needs. The model incorporated five dimensions: consumer demands (i.e., quality content, delivery, and service); superior  structural as the quality standard, i.e. “the required foundation that makes it possible to provide this level of content, delivery  and service” (MacDonald et al., 2001), which requires understanding the learner’s needs considering the learner’s motivation;  learning facilitators to establish a healthy collaborative learning environment; pedagogical strategies; conducting regular  assessment strategies and evaluation of learners; and ensuring the e-learning environment is convenient for learners. The third  dimension is the learner outcomes, e.g., lower cost for the learner, personal advantages, and achieving learning outcomes. The  fourth layer is the ongoing program evaluation and the fifth dimension is continual adaptation and improvement. The researchers  stated that these constructs are the recipe where WBL programs can succeed, and the model was empirically validated and tested  by the researchers (MacDonald et al., 2005). Another multi-dimensional model, constructed by Ehlers (2004), was introduced to  evaluate the quality of e-learning. Ehlers (2004) developed their model based on learners’ perspectives, where he stressed the  necessity to understand learners’ needs before starting any e-learning project. According to this model, the quality of e-learning  is a process of co-production between the learner and the learning environment to enable and empower the learner. There are diverse approaches, models and frameworks in the literature. For example, Boud and Prosser (2002) assumed that  higher e-learning quality can be measured by four aspects: learners’ engagement; context acknowledgement; the challenge for  learners; and the involvement of practice. Oliver (2005) studied quality assurance in e-learning and emphasized that there are  two main approaches: benchmarking and specification of standards. Benchmarking “compares the performance and outcomes  in one setting against that achieved” whereas the standards are the criteria used to judge performance. Pawlowki (2007) proposed  a quality adaption model by comparing the approaches of e-learning quality with ISO/IEC. The same approach was adopted by  Abdellatief et al. (2011) where they proposed a quality model from the developer’s perspective based on four variables: service  content, system functionality, information technology, and system reliability.  A framework to evaluate the quality of e-learning by Ireland et al. (2009) focused on improving the skills of academics and  considered this the main stimulant of e-learning quality. Another direction of assessing the quality of e-learning was by  establishing agencies and programs for the assurance of quality standards of e-learning, such as the Institute for Higher Education  Policy in the USA, the European Union e-learning program, and the Quality Assurance Agency QAA in the UK (Oliver, 2005).  Further, in Europe, a survey of the quality of e-learning was conducted to rate e-learning quality (Massy, 2002). A considerable  amount of research and effort has focused on the quality of e-learning. However, due to the complexity of e-learning systems,  diversity of e-learning stakeholders, and the generality of the ‘quality’ concept, there is uncertainty and ambiguity among what  actually constitutes a quality e-learning approach (Oliver, 2005). Additionally, it becomes challenging to identify precise  measurements suitable to evaluate e-learning systems based on quality approaches as the criteria vary from one organization to  another. 3 Development of Conceptual Model  In order to provide a general comprehensive definition of e-learning success measurement, the four approaches found for  evaluating e-learning and information systems from the literature review were considered in developing our model. Thus,  different perspectives have been considered based on their potential of evaluating the success of e-learning, in relation to: quality;  social factors (support system quality, learner quality and instructor quality); user beliefs (perceptions of satisfaction and  usefulness); acceptance (actual usage); and benefits of using the e-learning system. These dimensions encompass the main  components of the existing four approaches. The high order themes resulting from analysing the literature are depicted in Figure  1. Journal Pre-proof    5 Figure 1: The Simplified Conceptual Model for Evaluating the Success of E-Learning System Approach 1: DeLone and McLean Information Systems Success Model The current study model mainly adopts the constructs of the DeLone and McLean information systems success model and  extends it to included constructs and indicators from other models and theories to fit the context of e-learning. The constructs  adopted from this model are: 1. System Quality 2. Service Quality 3. Information Quality 4. Satisfaction  5. Use 6. Benefits  It is worth mentioning that the satisfaction construct is common to the DeLone and McLean and the satisfaction models, and use  is common to the DeLone and McLean model and TAM. The DeLone and McLean model was built to measure the success of information systems. Hence, a more customized version to  conform to the needs of e-learning systems is taken into consideration to develop our model. System quality is an important  determinant of the quality of e-learning, thus it was integrated into our model but is broken down into three constructs:  1. Technical System Quality  2. Educational System Quality  3. Support System Quality Technical system quality is related to issues like system reliability, availability, ease of use of system features, etc. Conversely,  educational system quality revolves around the existence of features like interactivity and communication components,  assessment material, and diversity of learning styles. Support system quality corresponds to supportive issues in the e-learning  system related to ethics and legal issues, and promotion of the e-learning system. More details about the definition of each  construct and the indicators used to measure each one will follow.  On the other hand, measuring benefits, at both individual and organizational levels, is a key construct for assessing e-learning  systems. However, measuring benefits at the organizational level requires “asking senior managers to assess the improved  profitability” (Petter et al., 2008). Therefore, the current study does not focus on such benefits, and considers only the individual  benefits for learners. The organizational benefits are beyond the scope of this study. Approach 2: Technology Acceptance Model TAM With respect to this approach, despite the plethora of TAM extensions, the two main constructs in this model are usefulness and  ease of use (Abdullah and Ward, 2016). Usefulness has been included in our model from TAM, which was successfully integrated  with the DeLone and McLean model in the study of Seddon (1997). In his extended model, usefulness was considered to be a  general perceptual measure of benefits and was operationalized as a determinant of user satisfaction. We integrated usefulness  in our model, as introduced by Seddon (1997).  In contrast to TAM, ease of use has not been operationalized as a separate construct in our model. Rather, it is an aspect related  to technical system quality. The effect of technical system quality, as a whole, on perceived satisfaction, perceived usefulness,  and use, is expected to be greater than the effect of ease of use on the same three constructs. Therefore, ease of use was  incorporated in our model as one of the indicators under the technical system quality construct.  Acceptance, in terms of intention to use or actual system use, was also incorporated in our model. However, DeLone and McLean,  in their updated model (2003), introduced intention to use as an alternative measure of use for some contexts, depending on the  stage of using the system. Researchers have suggested that intention to use is a valid measure at an early stage of implementing  a system. Since the e-learning system is in place in the context of the current study, it might be pointless to assess intention to  use. Thus, assessing the actual system use is appropriate in our case, and was added to our model. In addition, the e-learning  system in the context of the study is available for voluntary use, therefore system use can act as a determinant for benefits from  using the system. In other words, the benefits of the e-learning system cannot be achieved if learners do not use the system  (Seddon, 1997; Pituch and Lee, 2006; Lai et al., 2012; Alenezi and Karim, 2010; Abdullah and Ward, 2016). Journal Pre-proof    6 The part of TAM referred to as ‘attitude towards using’ was included in our model as an indicator related to the quality of learner  and instructor. Therefore, the learner and instructor attitudes toward using the system were incorporated as indicators under the  two constructs: learner quality and instructor quality.  In a survey study conducted by Abdullah and Ward (2016), the researchers studied 107 papers that extended TAM in the context  of e-learning. The results of the study showed that “Self-Efficacy, Subjective Norm, Enjoyment, Computer Anxiety, and  Experience are the most commonly used external factors of TAM”. Accordingly, the three indicators (self-efficacy, computer  anxiety, and experience) were included in our model as indicators for capturing learner quality. Subjective norm was added under  instructor quality. Enjoyment and pleasant experience were also incorporated under the perceived satisfaction construct. Approach 3: User Satisfaction Models  As mentioned earlier in chapter 2, there are different strategies for assessing user satisfaction at the micro level (assessing  satisfaction with a specific instance of the e-learning system) and at the macro level (assessing satisfaction with all technologies  introduced by the organization in relation to e-learning). In our case, this study adopted satisfaction at a micro level to assess  perceptions of users about a specific instance of e-learning. Enjoyable experience, satisfaction with system performance,  satisfaction with providing education needs, and overall satisfaction, are the indicators used in our model to represent this  construct.  Among the e-learning satisfaction models, the model of Sun et al. (2008) and the model developed by Ozkan and Koseler (2009)  provide potential contributions and good explanatory power for e-learning perceived satisfaction. From the two models, learner  quality and instructor quality were added as two separate constructs in our model.  The learner quality construct is used to capture different aspects of quality related to learners, such as the learner’s attitude,  anxiety, previous experience, and self-efficacy. Similarly, the instructor quality construct assesses the instructor’s quality  indicators, such as the instructor’s attitude, enthusiasm, prompt responsiveness to learners in the e-learning system, and  communication with learners.  In Sun et al.’s model, the authors assumed an environmental dimension (with two indicators, diversity in assessment and  interaction with others) as a determinant of satisfaction. This construct was renamed in our model as educational system quality,  as discussed earlier in the DeLone and McLean approach. Further, in Ozkan and Koseler’s model, ‘supportive factors’ was  introduced as a determinant of satisfaction, which was also included in our model as a separate construct, as mentioned earlier  in the DeLone and McLean approach. Approach 4: E-learning Quality Models  No specific construct was added from e-learning quality models. However, some indicators were incorporated in our model from  MacDonald et al.’s (2001), Attwell’s (2006), and Ehlers’ (2003) models: personalization, pedagogical strategies, learner needs,  security, interactivity, cost expectation benefit, and learning outcomes. Based on the results of previous studies and according to the four approaches, we propose a more comprehensive  multidimensional model for evaluating e-learning systems success (EESS model), a synthesis of the four previous approaches  listed above (i.e., the DeLone and McLean model, the TAM, the User Satisfaction Models, and the E-learning Quality Models)  depicted in Figure 2. The multidimensional model is comprehensive not based on the number of constructs but on the intention  to provide a holistic picture and different levels of success related to a broad range of success determinants, rather than focusing  on a specific construct. Figure 2: Multidimensional Conceptual Model for Evaluating E-learning System Success (EESS model) Journal Pre-proof    7 Why a comprehensive model is needed?  This study contributes to the growing body of e-learning systems success literature by providing a comprehensive  multidimensional model which considers the main dimensions and sub-dimensions of the four approaches. A comprehensive  model for evaluating e-learning system success is needed, for the following reasons. There is uncertainty and suspicion about what are actually the determinants of e-learning systems success. Hence, this study,  as a discrete activity, enumerates the literature related to e-learning system success to distil these factors. The DeLone and McLean literature provides us with an explicit model for measuring information systems success, but it has  to be broadened to include variables that fit the context of e-learning, enhance the explanatory power of the model, and focus  on the very important role of human and social factors in the success of such systems. Further, DeLone and McLean did not  empirically validate their model. Rather, the model was introduced as a framework for conceptualising information systems  success dimensions. They recommended that other researchers further develop and validate the model in different contexts. In the same manner, the TAM allows the acceptance and adoption of new technologies to be assessed, including e-learning  systems; however, acceptance does not guarantee success, but limits our understanding to aspects related to behaviour, while  there is a need to fully understand the whole picture of success. Over and above this, there is a need to consider all phases prior  to using the system (e.g., system design, information quality). Also of importance are phases during the utilization of the system  (e.g., usefulness and satisfaction), and after using the system (benefits of using the system). User satisfaction is an important predictor of success, but it should be integrated with other approaches to build a conceptual  bridge between the different phases of the system, the better to examine the important role of satisfaction in influencing the  learning benefits and assessing system success, and to maximize the predictive power of this construct. In relation to e-learning quality approaches, and given the diversity and complexity of e-learning systems, the spontaneity,  ambiguity, and generality of some of these approaches, coupled with a lack of theoretical underpinning, make adopting this  approach impractical and challenging to identify precise and suitable measurements of success. 3.1 Constructs of the Model  The proposed model is one which includes seven independent constructs: technical system quality, information quality, service  quality, educational system quality, support system quality, learner quality, and instructor quality. In addition there are four  dependent constructs: perceived satisfaction, perceived usefulness, system use, and benefits. More details about each construct  and the indicators used to reflect each construct supported by related studies, are found in Appendix 1. 3.2 Research Hypotheses The hypotheses about the connections in the research model with the corresponding discussions are presented in this section.  Each relationship between the constructs of the model is justified based on the assumptions empirically proved in the literature  of e-learning and information systems success. 3.2.1. Technical System Quality (TSQ)  Technical system quality is assumed in our model to be a determinant of three constructs: perceived usefulness, perceived  satisfaction, and use. In the original model of DeLone and McLean (2003) the researchers assumed that system quality directly  affects use and user satisfaction. Several researchers applied the DeLone and McLean model in the information systems context  and found a positive association between system quality and use (Halawi et al., 2007; Hsieh and Wang, 2007; Iivari, 2005). In  the e-learning systems context, system quality was also proved to be strongly related to use (Balaban et al., 2013; Garcia-Smith  and Effken, 2013; Lin, 2007; Marjanovic, 2016). Other researchers have studied the relationship between system quality and user satisfaction and shown the existence of positive  relationships between the two (Chiu et al. 2007; Halawi et al., 2007; Hsieh and Wang, 2007; Leclercq, 2007; Wu and Wang,  2006). Hassanzadeh et al., (2012), assumed that “whatever the technical quality of e-learning systems is more, user satisfaction  is higher” and supported this claim by empirical research.    For the relationship with usefulness, Seddon and Kiew (1994) and Seddon (1997) in their studies showed that “increases in  system quality will cause increase in usefulness” and found that system quality is an essential determinant of usefulness. Similar  findings were obtained by Sabherwal et al. (2006) and Liaw (2008).  Based on these findings, we therefore, assume that the higher the technical quality of the e-learning system, the more satisfied  the users are. Also, if users find the e-learning system compatible with their requirements, this would positively make users  utilize it and consider it useful. Thus, the following hypotheses are proposed:  H1a: Technical System Quality positively influences the perceived satisfaction with the e-learning system; H1b: Technical System Quality positively influences the perceived usefulness of the e-learning system; H1c: Technical System Quality positively influences the use of the e-learning system. 3.2.2. Information Quality (INQ) Information quality is a key and indispensable dimension in evaluating the success of information and e-learning systems due to  the essential role of information in achieving learning goals and the serious problems resulted from poor quality of information  (Al-Sabawy, 2013). The relationship between INQ and both use and user satisfaction came from the DeLone and McLean (2003)  model.  Based on the information systems literature, Rai et al. (2002) showed that there is a significant relationship between information  quality and use. The same result was also obtained by studies conducted by Halawi et al. (2007) for knowledge management  systems and Kositanurit et al. (2006) in health information systems. In the same context, Seddon and Kiew (1994) and Seddon  (1997) showed a significant relationship between information quality and perceived usefulness and user satisfaction. Journal Pre-proof    8 The relationships between information quality and each of the three constructs – use, satisfaction, and usefulness – have been  studied empirically by e-learning researchers. For example, Klobas and McGill (2010) and Eom et al. (2012) found a significant  relationship between information quality and both use and satisfaction with the LMS. The relationship between information  quality and perceived usefulness was found significant in the study of Chen (2010) with e-learning systems in an organizational  context, and a similar result found by Lwoga (2014) with web-based LMSs. Therefore, we may assume that improved quality of  information in the e-learning system will positively lead to an increase in perceived usefulness, perceived satisfaction, and system  usage. Thus, we hypothesise that: H2a: Information Quality positively influences the perceived satisfaction with the e-learning system; H2b: Information Quality positively influences the perceived usefulness of the e-learning system; H2c: Information Quality positively influences the use of the e-learning system. 3.2.3. Service Quality (SRQ) This construct was introduced as a new construct to the DeLone and McLean model (1992). The importance of this construct as  a measure of information systems success is related to the DeLone and McLean model (2003) who assumed in their model direct  relationships between service quality and both use and user satisfaction. Delivering services by IT personnel in the organization  whether related to an information system or to an e-learning system is also expected to be of great usefulness for learners and  positively influences their perceptions of satisfaction with the system.  The construct has been utilized in the information systems field. For example, the relationship between SRQ and satisfaction  was confirmed by Chen and Cheng (2009) in an online shopping system. The direct relationship between SRQ and use was found  significant by Wang and Liao (2008) in an e-government system.  Similarly, in the context of e-learning, the relationship between SRQ and satisfaction was found significant in the Roca et al.  (2006) and Ozkan and Koseler (2009) models. The relationship between SRQ and perceived usefulness proposed in the  conceptual model developed by Hagos et al. (2016) and Lwoga (2014) was shown empirically to be significant in the study  conducted by Al-Sabawy (2014) and Ngai et al. (2007). Accordingly, the following hypotheses are proposed: H3a: Service Quality positively influences the perceived satisfaction with the e-learning system; H3b: Service Quality positively influences the perceived usefulness of the e-learning system; H3c: Service Quality positively influences the use of the e-learning system. 3.2.4. Educational System Quality (ESQ) In developing a model for measuring the success of e-learning in Iranian universities, Hassanzadeh et al. (2012) found that  educational system quality positively and directly influences user satisfaction and indirectly the use of the system, which  indicates that educational features in the e-learning system, and facilities like discussion forums, chat-rooms, collaborative  learning tools, can result in user satisfaction and maximizing their usage of the e-learning systems. Social interaction was  employed as a key factor of success in computer supported collaborative learning (CSCL) and found to have a significant effect  on student learning (Xing et al., 2015). The relationship between educational system quality and perceived usefulness was found  significant for web-based e-learning systems in the study undertaken by Liu et al. (2005) and by Almaiah and Jalil (2016) for  mobile learning systems. Kim et al. (2012) and Mohammadi (2015) found a positive relationship between educational system  quality and satisfaction. In addition, the relationships between diversity in assessment materials, and learner interaction in the elearning system with perceived satisfaction, were found significant by Cidral et al. (2018). Further, the relationship between  educational system features and usefulness was found significant by Liu et al (2005) for a web-based e-learning system. The  same results were obtained by Liaw and Huang (2013) where a significant relationship between the interactive learning  environment construct with both perceived usefulness and perceived satisfaction was found. Therefore, the following hypotheses  about educational system quality are proposed: H4a: Educational System Quality positively influences the perceived satisfaction with the e-learning system; H4b: Educational System Quality positively influences the perceived usefulness of the e-learning system; H4c: Educational System Quality positively influences the use of the e-learning system. 3.2.5. Support System Quality (SUP) In the literature on e-learning system success, supportive issues in the e-learning system such as ethics and policies that outline  rules, regulations, guidelines and prohibitions to communicate within the e-learning system, assignments’ plagiarism rules, data  protection, and other legal and copyright issues of the uploaded materials in the e-learning system, in addition to the popularity  and policy followed by the organization, all these issues influence the learners significantly (Khan, 2005). For example, in the  empirical study conducted by Ozkan and Koseler (2009), the use of the LMS at Brunel University has increased significantly  due to the encouragement students and academics received from the university to use the LMS in their modules. The researchers  stated “the use of U-Link has increased significantly during the last three years … this is mainly because of the increasing  popularity of e-learning portals.” The researchers studied the relationship between supportive system issues and satisfaction and  found it significant. On the other hand, the organizational promotion of the e-learning system significantly and positively affected  employees’ satisfaction in the study conducted by Navimipour and Zareie (2015).  For the relationships between support system quality and both perceived usefulness and use, these were not empirically tested in  prior literature. However, we argue that the existence of supportive issues in an e-learning system is also expected to positively  influence utilizing the system and perceptions of usefulness. This is because more attention has been given recently to ethical  and legal issues, and new requirements have been introduced by data protection legislation. Further, considering the existence  of communication facilities (e.g., forums, chat, and email), data generated from chat and forums may express personal opinions,  personal data and personal biases that students are unlikely to want the outside world (through search engines) to know. Thus,  providing information prior to using the e-learning system can increase their awareness and significantly influence their Journal Pre-proof    9 perceptions toward the overall usefulness of the system. Moreover, the popularity of the e-learning system, and the policy  followed by the organization to promote their e-learning system, play an important role in increasing the usage of the system by  academics and learners. Therefore, we propose the following hypotheses: H5a: Support System Quality positively influences the perceived satisfaction with the e-learning system; H5b: Support System Quality positively influences the perceived usefulness of the e-learning system; H5c: Support System Quality positively influences the use of the e-learning system. 3.2.6. Learner Quality (LER) This construct was successfully operated in several models developed by prior e-learning researchers. Several researchers  examined a subset of the learner quality construct, for example, the learner’s self-efficacy was studied by Ong et al. (2004) and  a significant relationship with perceived usefulness was found. The same result was achieved by Park (2009). McGill and Klobas  (2009) studied the relationship between learner attitude toward LMS use and LMS utilization and found it significant.  Additionally, the relationships between student involvement and both use and satisfaction were found significant in the study of  Klobas and McGill (2010). Also, the relationships between self-efficacy and a learner’s computer anxiety with perceived  usefulness were studied by Chen and Tseng (2012).  The relationship between learner and perceived satisfaction was found significant in the models of Sun et al. (2008) and Ozkan  and Koseler (2009). Given the positive relations of the indicators associated with the variety of learner’s characteristics, it is  more likely that the quality of the learner will influence perceived usefulness and use of the system. Thus, we propose the  following hypotheses: H6a: Learner’s Quality positively influences the perceived satisfaction with the e-learning system; H6b: Learner’s Quality positively influences the perceived usefulness of the e-learning system; H6c: Learner’s Quality positively influences the use of the e-learning system. 3.2.7. Instructor Quality (INS) The instructor’s role in the success of e-learning has received attention from researchers in the e-learning arena. To clarify, the  model developed by Sun et al. (2008) researched the relationship between the instructor dimension, using two indicators  (instructor response timeliness, instructor attitude toward e-learning), and satisfaction, and found it positively significant. Similar  results were obtained by Cidral et al. (2018) where a positive relationship found between instructor attitude toward e-learning  and user’s satisfaction. Lwoga (2014) employed instructor quality as a separate construct and confirmed a positive significant  relationship between instructor quality and both perceived usefulness and user satisfaction. Also, instructor quality has been  found to have a significant effect on learners’ satisfaction with an e-learning system in the study conducted by Mtebe (2018). Subjective norm as an indicator related to instructor quality was studied in the models developed by Park (2009) and Roca et al.  (2006), and significant relationships with usefulness and satisfaction were found respectively. Little research has been found to  investigate the relationship between instructor quality as a stand-alone construct and e-learning system use. Nevertheless, McGill  and Klobas (2009) studied the correlation between instructor norms and LMS utilization and found it positively significant. In  our research, we assume that aspects related to instructors, such as positive attitude, enthusiasm, recommendation to students,  involvement with different levels of activities (e.g. interactive and communication and responsiveness to students) are also likely  to influence utilizing the e-learning system. Based on that, we propose the following hypotheses:  H7a: Instructor’s quality positively influences the perceived satisfaction with the e-learning system; H7b: Instructor’s quality positively influences the perceived usefulness of the e-learning system; H7c: Instructor’s quality positively influences the use of the e-learning system. 3.2.8. Perceived Satisfaction (SAT) It is clear that satisfaction has strongly proved its validity and reliability as an essential measurement of the success of both  information systems and e-learning systems. In our study model, we have assumed that user satisfaction is a determinant of the  benefits construct. The influence of user satisfaction on the benefits achieved from the system was empirically found significant  in the DeLone and McLean information systems success model (2003). Hassanzadeh et al. (2012) explained that when users of  the e-learning system are more satisfied, they are using the system and the benefits of using the system will be achieved. Cidral  et al. (2018) found that perceived satisfaction explained 43.3% of the variance of individual impacts denoting a significant  relationship between the two. The same results were obtained by Eom et al. (2012) and Hassanzadeh et al. (2012). Therefore,  we assume the following hypothesis: H8: Perceived Satisfaction toward the e-learning system positively influences students’ benefits. 3.2.9. Perceived Usefulness (USF) Usefulness was used by Davis (1989) as a key determinant construct in the technology acceptance model. Acceptance is a  necessary element for measuring the success of information and e-learning systems (Davis, 1989; Roca et al., 2006). The model  of the study expects that perceived usefulness of e-learning could positively influence three constructs: perceived satisfaction,  use, and students’ benefits. The findings from the literature empirically support these relations. In the study conducted by  Arbaugh (2000) it was hypothesized that “Perceived usefulness of the course software will be positively associated with student  satisfaction with an Internet-based course”, and this hypothesis was supported. Equivalently, the study of Seddon (1997) in  information system success, Al-Sabawy (2013) in e-learning systems success, and Limayem and Cheung (2008), all found that  perceived usefulness significantly and directly affect user satisfaction.  Correspondingly, if students perceived that the e-learning system is useful to them, they are more likely to use it. This relationship  has been assessed in several e-learning studies, for example, Islam (2013), Pituch and Lee (2006), Raaij and Schepers (2008),  Sandjojo and Wahyuningrum (2015), and Šumak et al. (2011). Journal Pre-proof    10 Previous studies highlighted the direct significant relationship between usefulness and net benefits (Hwang et al., 2008);  usefulness and organizational benefit (Park et al., 2011); usefulness and individual impact (Lee et al., 2011); usefulness and both  individual and organization impact (Hasan et al., 2017). We, therefore, propose the following hypotheses:  H9a: Perceived Usefulness positively influences the perceived satisfaction with the e-learning system; H9b: Perceived Usefulness positively influences the use of the e-learning system; H9c: Perceived Usefulness positively influences students’ benefits. 3.2.10. System Use (USE) Actual system usage is a measure common to the information systems success model of DeLone and McLean (2003) and the  TAM of Davis (1989). In the systematic literature review study conducted by Petter et al. (2008), it was reported that ‘use’ has  a moderate association with benefits of using the system. Through prior studies, the relationship between use and benefits of the  system was found significant (Chen, 2012; Garcia-Smith and Effken, 2013; Hou, 2012). At an organizational level, the use of elearning systems to deliver training courses for employees proved to directly and positively affect the net benefits of the company  (Chen, 2012). Other studies found similar results (Halawi et al., 2007; Kositanurit et al., 2006; Zhu and Kraemer, 2005).  Accordingly, we expect that using the system can positively enhance students’ benefits of increased knowledge, saving time,  and managing the learning process systematically. Given support from prior research, the current study proposes the following  hypothesis: H10: The use of the e-learning system positively influences students’ benefits. Based on the literature and the above relationships, the components of the EPSS model were linked to reflect the hypotheses and  show the directions of the assumed relationships, as depicted in Figure 3. Figure 3: Evaluating E-learning System Success (EESS Model) 4 Research Methodology Quantitative methods are used to test theoretical models and hypotheses, and a quantitative analytical survey was adopted in this  study. The measurement items were obtained from the literature review and were deemed to represent all aspects of the construct.  As a complementary step, experts’ opinions regarding the items adopted to reflect each construct were solicited (Walker and  Fraser, 2005). E-learning experts, through a questionnaire, were asked to assess the importance of each factor in the model based  on a 3-point scale (Lawshe, 1975): essential, important (but not essential), and not relevant. In addition, an open-ended question  was added “What are the factors that are important for the evaluation of e-learning system success?” to give experts the  opportunity to submit their opinions about factors that might not be included in the close-ended question. Cronbach’s alpha  coefficient was employed to determine reliability of the questionnaire. According to the results of this test, the Cronbach’s alpha  coefficient value for the experts’ questionnaire was 0.933. Based on the responses received, the items (overall usefulness and  overall satisfaction) were added to the two constructs (perceived usefulness and perceived satisfaction) respectively. A statement  was added to the support system quality construct ‘Providing information about accessibility of content and any other personal  data in the e-learning system’. Additionally, the interactivity statement was broken down into two: one for the existence of  interactivity and communication features and one for the effective communication to provide good coverage for the educational  system quality construct. Based on experts’ feedback, measurements were confirmed, and no item was deleted. The final items  numbered 58.  An online survey was collected from students enrolled in the Moodle LMS provided by the University of Warwick, the UK for  the purposes of e-learning due to accessibility of data. Moodle was selected to test the model of the study because the University  of Warwick has adopted Moodle as the main e-learning system designed to support teaching and learning materials and activities,  and to provide a number of interactive activities including forums, wikis, quizzes, surveys, chat and peer-to-peer activities,  serving most of the departments and students. In addition, Moodle is widely used in the education sector generally and in higher  education specifically. Journal Pre-proof    11 A total of 588 responses were received. After collecting the data, a preliminary data analysis was performed as a first step to  check for any missing data, unengaged responses, outliers, and normality. As a result, 563 responses were considered valid for  further analysis. The demographic information for the study sample is distributed as follows (Table 1). Sample Characterization Frequency Percent Male 259 46% Female 304 54% Gender Total 563 100% < 21  331 58.8% 21-30 218 38.7% >30 14 2.5% Age Total  563 100% Undergraduate  495 87.9% Postgraduate  68 12.1% Enrolled Course Total  563 100% Less than a year 291 51.7% 1-2 years 133 23.6% More than 2 years 139 24.7% Experience with the  e-learning system Total  563 100% One module 32 5.7% More than one 531 94.3% Number of online  modules taken Total  563 100% Faculty of Medicine  88 15.63% Faculty of Science and Engineering 253 44.94% Faculty of Social Sciences 222 39.43% Field of study Total  563 100% Access learning resources only. 89 15.81% Access learning resources, and accomplish and  submit assignments or quizzes only. 285 50.62% Access learning resources, and interact with my  instructors and colleagues only. 36 6.93% Access learning resources, accomplish and  submit assignments or quizzes, and to interact  with my instructors and colleagues. 153 27.18% Nature of using the  e-learning system Total  563 100% Table 1: Sample Characterization 5 Analysis and Results Researchers use different statistical methods to develop and confirm their research findings. Hair et al. (2012) distinguished  between two generations of the application of statistical methods. Factor analysis and regression analysis were predominant and  extensively used in the first generation. There was a shift since the 1990s toward more sophisticated multivariate methods such  as structural equation modelling (SEM), which has dominated the research landscape in the second generation (Goggins and  Xing, 2016). There are two types of SEM, covariance-based SEM (CB-SEM) and composite-based SEM, also known as partial least squares  SEM (PLS-SEM). In this research, PLS-SEM was used as a key technique to test the study model due to the complexity of the  model – 11 constructs, 58 indicators, and 26 relationships – since PLS-SEM fits such kind of models (Hair et al., 2012). SmartPLS  version 3.0 was utilized to test the measurement and structure model. 5.1 Measurement Model  The measurement model was assessed using the following criteria. Step1: Indicator Reliability:  outer loading for the indicator should be ≥ 0.70 (Hair et al., 2012). Step2: Internal Consistency Reliability: using two tests: Cronbach's alpha (α) and Composite reliability (CR). The cut off value  is ≥ 0.70 for both tests (Urbach and Ahlemann, 2010). Step3: Validity: 1. Convergent Validity: the average variance extracted AVE should be ≥ 0.50 (Fornell and Larcker, 1981). 2. Discriminant Validity: using three tests: 2.1Fornell-Larcker criterion (Fornell and Larcker, 1981); 2.2Cross-loadings (Urbach and Ahlemann, 2010); 2.3The Heterotrait-Monotrait ratio (HTMT) (Henseler et al., 2015). First, indicators with loadings less than 0.70 were analysed. The technique used to deal with them was based on the suggestion  of Hair et al. (2012) which indicates that: If the outer loading is < 0.40 delete the indicator; If the outer loading is ≥ 0.70 retain the indicator; If outer loading is ≥ 0.40 but < 0.70 then analyse the impact of indicator deletion on AVE and composite reliability: if  measures already meet the thresholds then retain the indicators, otherwise consider deleting the indicator. Journal Pre-proof    12 As a result, seven items fail to meet the minimum criteria and have a significant impact on AVE and were deleted. These are  ease to learn, system availability, system reliability, system fulfilment, security, personalization from Technical System Quality  construct, and easier interaction and communication from Benefits construct. Second, Cronbach's alpha α, CR, and AVE were retrieved to test the internal consistency reliability and validity. Table 2 shows  that all values met the minimum requirement for internal consistency reliability. Also, the average variance extracted AVE  employed to assess the convergent validity was ≥ 0.50 for all constructs. Constructs Cronbach's alpha α ≥ 0.70 Composite Reliability CR ≥ 0.70 AVE ≥ 0.50 TSQ 0.830 0.880 0.590 INQ 0.860 0.900 0.550 SRQ 0.850 0.890 0.630 ESQ 0.710 0.800 0.520 SUP 0.800 0.850 0.580 LER 0.840 0.890 0.620 INS 0.750 0.830 0.510 SAT 0.900 0.930 0.770 USF 0.900 0.930 0.770 USE 0.910 0.940 0.790 BNT 0.850 0.900 0.690 Table 2: Internal Consistency Reliability and Convergent Validity Results Third, the correlation matrix for the Fornell-Larcker method is presented in Table 3. The AVE should explain the same construct  more than the other constructs. In other words, the values on the diagonal should be higher in the same construct compared with  other constructs. It is clearly shown that the diagonal values are larger than the other values inside the one column. BNT ESQ INQ INS LER SAT SRQ SUP TSQ USE USF BNT 0.83 ESQ 0.35 0.72 INQ 0.56 0.37 0.74 INS 0.56 0.37 0.44 0.71 LER 0.69 0.33 0.67 0.54 0.79 SAT 0.73 0.33 0.68 0.52 0.58 0.88 SRQ 0.32 0.14 0.43 0.29 0.35 0.41 0.79 SUP 0.50 0.37 0.42 0.37 0.52 0.49 0.32 0.76 TSQ 0.54 0.32 0.52 0.45 0.62 0.63 0.41 0.36 0.77 USE 0.48 0.31 0.34 0.29 0.47 0.46 0.15 0.36 0.33 0.89 USF 0.75 0.31 0.59 0.49 0.69 0.73 0.32 0.51 0.54 0.55 0.87 Table 3: The Fornell-Larcker Discriminant Validity Correlation Matrix The cross loadings formed the second method utilised to assess the discriminant validity. The cross loadings were retrieved to  assess the loading of each indicator (Appendix 2). It can be clearly seen that each indicator loads highest on the construct it is  associated with. The HTMT is a criterion proposed by Henseler et al. (2015) to assess the discriminant validity, because the  Fornell-Larcker criterion and cross loadings are insufficiently sensitive to detect many discriminant validity problems.  HTMT  is equal to average Heterotrait-Heteromethod correlation relative to the average Monotrait-Heteromethod correlations. The  Heterotrait-Heteromethod correlations are correlations of indicators across constructs measuring different phenomena, while the  Monotrait-Heteromethod correlations are correlations of indicators measuring the same construct. The HTMT values were  retrieved using SmartPLS software as shown in Table 4. All HTMT values are within the accepted threshold values ≤ 0.90. BNT ESQ INQ INS LER SAT SRQ SUP TSQ USE USF BNT ESQ 0.38 INQ 0.65 0.41 INS 0.68 0.48 0.52 LER 0.79 0.37 0.75 0.66 SAT 0.83 0.36 0.77 0.61 0.81 SRQ 0.37 0.18 0.51 0.35 0.41 0.47 SUP 0.52 0.35 0.42 0.41 0.52 0.47 0.37 TSQ 0.64 0.38 0.84 0.55 0.71 0.72 0.50 0.37 USE 0.55 0.32 0.38 0.33 0.52 0.50 0.17 0.34 0.36 USF 0.83 0.33 0.66 0.57 0.76 0.80 0.36 0.50 0.62 0.61 Table 4: The HTMT Correlation Matrix A summary of the results of the measurement model assessment is presented in Appendix 3. 5.2 Structural Model  The structural model has been assessed, as suggested by Hair et al. (2012), using the following steps: 1. Assess the structural model for collinearity issues (VIF < 5); Journal Pre-proof    13 2. Assess the significance and relevance of the structural model relationships (p <0.05); 3. Assess the level of R2 (The cut off levels are: 0.190 weak; 0.333 moderate; and 0.670 substantial); 4. Assess the level of Q2 (cut-off point larger than zero); 5. Assess the model’s fit (SRMR ≤0.08; RMStheta ≤ 0.12). First, collinearity symptoms were assessed by generating the variance inflation factor VIF. A VIF value ≥ 5 indicates a potential  collinearity problem. The retrieved VIF values are all within the accepted threshold values (VIF < 5). Thus, collinearity was not  a problem in our data. Second, the path coefficients (β values) of the relationships between the constructs in the model are shown in Figure 4. Figure 4: Structural Model Path Coefficients The significance of the path coefficient is assessed using the algorithm of bootstrapping in PLS. 5000 bootstrap samples were  generated. The t and p values are used to test whether the path coefficients β values are statistically significant at 5% error  probability. The statistical significance level at 5% indicates that p-value has to be < 0.05 to accept the hypothesis and t value >  1.65. Results of the bootstrapping algorithm are shown in Table 5. H Path β coefficients T Statistics P Values Support H1a TSQ → SAT 0.085 2.160 0.020 Accepted H1b TSQ → USF 0.079 1.750 0.040 Accepted H1c TSQ → USE 0.043 0.690 0.250 Rejected H2a INQ → SAT 0.199 4.760 0.000 Accepted H2b INQ → USF 0.146 3.050 0.000 Accepted H2c INQ → USE -0.010 0.160 0.440 Rejected H3a SRQ → SAT 0.077 2.940 0.000 Accepted H3b SRQ → USF 0.000 0.010 0.500 Rejected H3c SRQ → USE -0.042 1.050 0.150 Rejected H4a ESQ → SAT 0.009 0.340 0.370 Rejected H4b ESQ → USF 0.002 0.040 0.480 Rejected H4c ESQ → USE 0.143 3.430 0.000 Accepted H5a SUP → SAT 0.056 1.900 0.030 Accepted H5b SUP → USF 0.179 5.330 0.000 Accepted H5c SUP → USE 0.125 2.600 0.000 Accepted H6a LER → SAT 0.490 11.860 0.000 Accepted H6b LER → USF 0.389 7.440 0.000 Accepted H6c LER → USE 0.352 5.130 0.000 Accepted H7a INS → SAT 0.085 2.850 0.000 Accepted H7b INS → USF 0.109 2.880 0.000 Accepted H7c INS → USE -0.005 0.100 0.460 Rejected H8 SAT → BNT 0.388 8.900 0.000 Accepted H9a USF → SAT 0.277 6.650 0.000 Accepted H9b USF → USE 0.432 8.040 0.000 Accepted H9c USF → BNT 0.573 16.130 0.000 Accepted H10 USE → BNT 0.066 2.260 0.010 Accepted Table 5: Results of Path Analysis and Hypothesis Testing Journal Pre-proof    14 Third, the coefficient of determination R2 has been used to measure the explained variance of the latent dependent variables  relative to the total variance. As can be seen in Figure 4, perceived satisfaction, perceived usefulness and benefits of the elearning system moderately to substantially explained 64.7% of the variance in benefits of the e-learning system. A substantial  percent (71.4%) of e-learning satisfaction was explained by seven constructs: technical system quality, information quality,  service quality, educational system quality, learner quality, instructor quality, support system quality, and perceived usefulness.  Five constructs were the main determinants of perceived usefulness, namely technical system quality, information quality, learner  quality, instructor quality, and support system quality. These five constructs together explained 54.2% of the variance in  perceived usefulness, which is considered moderate. Finally, educational system quality, support system quality, learner quality,  and perceived usefulness explained moderately 34.4% of the system use construct, with perceived usefulness being the strongest  determinant followed by learner quality, educational system quality, and support system quality respectively. Fourth, assessment of the predictive relevance Q2 results was done using Blindfolding in SmartPLS, the omission distance D  was 7. Table 6 illustrates the results. Predictive Relevance Q2 Constructs Construct Crossvalidated Communality Construct Crossvalidated Redundancy BNT 0.47 Strong predictive power 0.42 Strong predictive power INQ 0.40 Strong predictive power - INS 0.28 Moderate predictive power - SAT 0.57 Strong predictive power 0.52 Strong predictive power LER 0.44 Strong predictive power - ESQ 0.26 Moderate predictive power - USE 0.59 Strong predictive power 0.25 Moderate predictive power SRQ 0.43 Strong predictive power - SUP 0.30 Moderate predictive power - TSQ 0.38 Strong predictive power - USF 0.56 Strong predictive power 0.39 Strong predictive power Table 6: Results of Q2 Level Assessment All values of Q2 exceeded the cut-off point (larger than zero). The crossvalidated redundancy measures the capability of the path  model to predict the endogenous measuring items indirectly from the prediction of their own latent variables using the related  structural relations. It is only computed for the endogenous variables. Table 6 shows that the model has strong predictive  relevance for the endogenous constructs SAT, BNT, and USF (the cut-off value for strong predictive is Q2 ≥ 0.35) (Hair et al.,  2012). Finally, USE has a moderate predictive power with Q2 = 0.250.  In terms of the predictive relevance of the cross-validated communality, Q2 values were calculated through the measurement  model’s capability to assess the path model directly from their own latent variable. The Q2 values in Table 6 above show 8 with  strong prediction power and three with moderate prediction power.  Results from both procedures suggest that the model has  considerable predictive power. Finally, the last step after examining the predictive power of the model is to assess the model fit. Model fit addresses the issue  of how well the model that best represents the data reflects the underlying theory (Hooper et al., 2008). In PLS-SEM, the model  fit assessment was done using the following three criteria. 1. Standardised Root Mean Square Residual (SRMR) which is an absolute measure of model fit proposed to avoid model  misspecification (Henseler et al., 2014). The cut-off value used for SRMR is ≤0.08. Using SmartPLS software, the SRMR  for the current study is 0.070 which is less than the cut off value suggested in the literature. 2. Root Mean Square Residual (RMStheta) assesses “the degree to which the outer model residuals correlate” (Henseler et al., 2014). This measure should be ≤ 0.12 to indicate a good model fit (Hair et al., 2012; Henseler et al., 2014). Using SmartPLS  RMStheta is 0.11 which indicates a good model fit. 3. The model’s Goodness-of-Fit (GoF) is our last criterion to assess the overall fit of the model. It is defined as “how well the  specified model reproduces the observed covariance matrix among the indicator items” (Hair et al., 2012) The purpose of  GoF is to account for the model at both levels, that is, the measurement model and the structural model with a focus on the  overall performance (Henseler and Sarstedt, 2013). There is no global fit measure in PLS. Nevertheless, researchers suggest  a global GoF defined as the geometric mean of the average communality and average R2 for endogenous constructs  (Tenenhaus et al., 2005) given using this formula:  GoF= 𝑅2 ∗ 𝑎𝑣𝑒𝑟𝑎𝑔𝑒𝑐𝑜𝑚𝑚𝑢𝑛𝑎𝑙𝑖𝑡𝑦 The GoF cut off values used in this study are (Wetzels et al., 2009): GoF less than 0.1 No fit; GoF between 0.1 to 0.25 Small; GoF between 0.25 to 0.36 Medium; GoF greater than 0.36 Large. The model’s Goodness-of-Fit for the current study as calculated using the formula is 0.49 which is deemed large. Journal Pre-proof    15 6 Discussion  Hypotheses H1 and H2a gained empirical support. Thus, aspects related to the technical quality of the system such as ease of  using the e-learning system, capability of the system to meeting users’ requirements, flexibility of the system to interact with,  integration and consistency between the different components of the system, and the existence of features and functions the users  need are all important aspects and contribute to the overall satisfaction and perceptions toward the usefulness of the system. The  results support the studies of Al-Sabawy (2013), Cidral et al. (2018) and Islam (2011). The results of testing hypothesis H1c  showed that this hypothesis is not supported. In other words, technical system quality did not significantly affect the use of the  e-learning system. This suggests that students still use the specific e-learning platform the university adopted regardless of its  quality. A similar insignificant relationship was found by Aparicio (2017) and Cidral et al. (2018). A possible reason for the nonsignificant relationship could be that aspects of system quality are less important for using the system, in contrast to the  importance of making students more satisfied and impacting their belief about the usefulness of the system. Hypotheses H2a and H2b were accepted. This confirms that information quality is a determinant of perceived satisfaction and  perceived usefulness. For example, information quality aspects such as providing students with sufficient and required  information, concise and clear information, updated content, and providing students with attractive design of content are  important to make students have an enjoyable and pleasant experience with e-learning and contribute to their overall satisfaction.  In addition, organizing the content and information into logical and understandable components in the e-learning system allows  students to accomplish their learning tasks quickly. These results corroborate the results obtained by Hassanzadeh et al. (2012),  who found that information quality has the most direct effect on user satisfaction.  H2c was rejected, and this is interpreted as  evidence that providing users with high quality information does not influence their use of the e-learning system.  One reason  for that could be because students depend on the system to access the Lecture Capture tool available via Moodle and to use the  online submission system to submit their assignments. Others do some exams in class and depend on the system to access  learning materials during revision periods. Students also need access to lecturers’ handouts and resources which are only  available through the system.   Statistical results showed that there is a positive relationship between service quality and perceptions of satisfaction (H3a). This  result suggests that providing quality services to students may potentially increase their level of satisfaction toward the e-learning  system. Thus, it is crucial to have technical personnel who are available when needed, have control over the technology, support  students by providing guidance and training on how to use the system, and able to provide solutions for technical issues students  face with the e-learning system, and who can consequently satisfy their needs, generate positive feelings, and influence their  overall satisfaction about the system. This result supports other researchers for example, Al-Sabawy (2013), Almarashdeh et al.  (2010), Mtebe and Raphael (2018), Roca et al. (2006), Sun et al. (2008), Sandjojo and Wahyuningrum (2015). H3b and H3c did  not gain support, in other words, the quality of services delivered to students by IT personnel does not contribute to students’  feeling toward the usefulness of the e-learning system and the utilization of the system. This result was consistent with several  studies where researchers did not find any link between service quality and usefulness, for example, Gorla and Somers (2014),  Lwoga (2014), Motaghian et al. (2013) and Zaidi et al. (2014). Contrary to our prediction, H4a and H4b failed to receive support. This result is inconsistent with the result obtained by  Hassanzadeh et al. (2012) who argued, however, that this construct influences users’ satisfaction less than the other quality  factors. The same results were obtained by Mohammadi (2015). However, H4c was accepted. Thus, aspects of educational  system quality such as the existence of communication tools and interactivity features, diversity of learning styles, and providing  assessment materials to students (e.g., quizzes and assignments) have a strong influence on utilizing the e-learning system, thus  students are more likely to use the e-learning system. This is in parallel with the findings of Pituch and Lee (2006).   H5a, H5b, and H5c were supported. Thus, providing information about ethical and legal issues prior to using the e-learning  system can increase their awareness and significantly influence the success of the system. H5b and H5c were not empirically  tested in prior studies, however, evidence from the literature (Khan, 2005; Ozkan and Koseler 2009; Navimipour and Zareie,  2015) can be compared to our results. H6a, H6b, H6c were supported. The results are in parallel with previous studies of Üstünel (2016), Ozkan and Koseler (2009),  Sun et al. (2006) and Chen and Yao (2016), who employed learner construct in their models of e-learning systems evaluation.   The finding confirms the vital role the learner plays in the success of e-learning. Learners, who have a positive attitude toward  using e-learning systems in their study, are more satisfied with the system. Students’ experience and familiarity with the system,  and ability to use the system and perform tasks (self-efficacy), can stimulate their positive attitudes toward the e-learning system,  thus their overall satisfaction about it. The relationship between the learner as a stand-alone construct and system use has not  been tested before, although similar results were reported in several studies between learner sub-dimensions and use of the system  or intention to use the system (Kim and Park, 2018; Mohammadi, 2015; Sánchez and Hueros, 2010; Teo et al., 2019). Statistical results support hypotheses H7a and H7b. Since the instructor is the key person who is important to learners in the elearning environment (Cheng, 2012), students’ satisfaction with e-learning is positively influenced by the instructor quality. In  the study conducted by Kim et al. (2012), researchers stated that “The instructor is the most important success factor in e-learning  ... Instructors increase user satisfaction and encourage students to become engaged in various learning opportunities”. However,  the instructor’s communication, responsiveness, and attitude toward the e-learning system did not affect students’ usage of the  system. This result contradicts prior studies where support was found on the relationship between the instructor and usage or  intention to use the e-learning system (Abbas, 2016; Lee et al., 2009; Nair et al., 2015). However, it is consistent with Zhao et  al. (2019) where no support was found between instructor and continued use intention. A possible reason for this insignificant  relation could be because students are very dependent on Moodle to access the resources instructors upload and to submit  assignments using the online submission system. Thus, aspects related to instructors were strongly related to their perceived  satisfaction and usefulness of the system but not their utilization of it. Journal Pre-proof    16 H8 was supported, thus, the more satisfied the user is, the greater the benefits and impacts on students will be achieved. The  significant relationship is in line with studies on e-learning (Aparicio et al., 2016; Cidral et al., 2018; Seta, 2018; Urbach et al.,  2010; Wu and Wang, 2006). The results of the study strongly support H9a, H9b, and H9c. As a result, perceived usefulness is a  key determinant of students’ perceived satisfaction, perceived usefulness, and system use. Clearly, students would feel satisfied  if they feel that the system enhances their learning performance and activities, help them to accomplish their tasks easily and  smoothly with less effort, hence learn more effectively. Also, if students perceive that the e-learning system is useful to them,  they are more likely to use it. The results overlap with several e-learning studies that investigated this relationship (Al-Sabawy,  2013; Almarashdeh et al., 2010; Ghazal et al., 2018; Islam, 2013; Lwoga, 2014; Sun et al., 2008). In view of the fact that benefits are achieved if learners use the e-learning systems hypothesis H10 has gained empirical support.  However, it has less effect on benefits. If using the e-learning system is in line with students’ needs, then students will be more  successful in the modules, interaction and communicant are easier, and learning goals are achieved. Furthermore, the e-learning  system will save their time in searching for materials and cut down expenditure such as paper. Thus, the higher the usage of the  e-learning system the more benefits are achieved. The result is in line with literature (Aparicio et al., 2016; Cidral et al., 2018;  Urbach et al., 2010). 7 Conclusion and Implications This research aims to investigate the factors that are considered for the evaluation of e-learning system success and has led to  the development of an e-learning success model that incorporates these factors. To test the model, an empirical study was  conducted. The contribution of this research is multifaceted and provides theoretical contributions as well as practical  contributions as follows. 7.1 Theoretical Implications The first contribution of this study revolves around developing a multi-dimensional, comprehensive model for evaluating the  success of e-learning. The model was developed based on an intensive review of literature and analysis of four approaches for  evaluating the success of e-learning: the DeLone and McLean information systems success model, the Technology Acceptance  Model (TAM), user satisfaction models, and e-learning quality models. This new model is believed to be comprehensive because  different perspective have been considered in relation to different aspects of quality, social factors, acceptance, usefulness,  satisfaction, and benefits of using the e-learning systems, and these encompass the main components of the existing approaches.  Second, this study took a step forward and offers an empirical investigation of the model developed incorporating the factors  that influence the success of e-learning systems. Seven types of quality factors, as antecedents of perceived satisfaction, perceived  usefulness, use, and benefits, are proposed and empirically examined, namely technical system quality, information quality,  service quality, educational system quality, support system quality, learner quality, and instructor quality. Collectively, all these  factors are valid and important measures and contribute to the identification of e-learning success factors which is the second  contribution of this research. The current research has also investigated new relationships which have not been empirically tested  before (e.g., the relationship between learner quality, instructor quality, educational system quality and support system quality,  with system use and perceived usefulness). Prior studies have referred to the relation with satisfaction only. As far as we know,  however, this is one of the first studies to provide a comprehensive identification of e-learning success factors and empirically  examine the relationships between the measures in one single model, which is the third contribution of this study.  The fourth contribution revolves around the performance of the developed model. The model showed a strong predictive power  among perceived usefulness, perceived satisfaction, and benefits, and moderate predictive power for use. The model has  substantially explained 71.4% of the variation of e-learning perceived satisfaction, moderately to substantially explained the  variance of benefits and perceived usefulness with the amounts of 65% and 54.2% respectively. It has moderately explained  34.1% of the variation of e-learning use, which compared to prior models considered a novelty.  Finally, the research presents important theoretical contributions in the information systems field and e-learning success theories.  It contributes to the DeLone and McLean model literature, TAM, and e-learning satisfaction and success theories by proposing  an extension of the original DeLone and McLean information systems success model. Additionally, this study confirms the  validity of DeLone and McLean information systems success model for evaluating the success of e-learning systems in the  context of the UK. 7.2 Practical Implications   Considering the fact that approximately 99% of higher education institutes use an LMS (e.g., Moodle, Blackboard, WebCT,  Desire2Learn) on the one hand, and the considerable investments in the use and delivery of these systems to support and facilitate  learning process on the other hand (Fathema et al., 2015), the study results shed light on important issues and recommendations  that should be taken into consideration to improve the perceptions of satisfaction and usefulness, use, and benefits of the elearning systems. The study provides practitioners with several practical contributions as follows. 1. With respect to the fact that many universities start with a commercial or open source LMS, the study results stress the  necessity for periodically surveying their students. As a result, continuous improvement of these systems is required to  address any issues and shortfalls. 2. The study revealed that the existence of communication and interactivity features, assessment and evaluation materials,  and the diversity of learning styles positively influence utilization of the e-learning system, and aid students to be more  engaged in their learning. Therefore, more efforts should be directed toward effectively using these tools to exploit the  full capabilities of the e-learning system. 3. The study reveals that instructor quality has a significant effect on the perceptions of satisfaction and usefulness of the  system. As a result, proper and extensive training of instructors prior to using the e-learning system is vital. This will Journal Pre-proof    17 aid instructors to gain an in-depth understanding and confidence using the e-learning system, in addition to increasing  their awareness of the full features of the system. 4. The findings of this study suggest increasing awareness among students about the usefulness and benefits of the elearning system to increase its usability and popularity. This can be achieved by delivering workshops and training.  Therefore, learners’ attitudes toward the e-learning system, learners’ self-efficacy, and their experience with the elearning system, are all increased, thus increasing the perceptions of usefulness and satisfaction, and the usage of the elearning system. 5. Our results indicate that supportive issues in the e-learning system have a significant and positive influence on all of  the following: system use, perceived usefulness, and perceived satisfaction of the e-learning system. Considering the  wealth of resources and information available on the Internet, these results indicate that faculty members and  administrators should provide sufficient information to students regarding plagiarism rules and regulations when  submitting assignments. This can be delivered by providing extra modules on this matter through the e-learning system.  Furthermore, copyright issues, accessibility of content, permission for viewing the course materials, and intellectual  property issues, all should be clearly delivered to students using the e-learning system. 6. The results of this study draw the attention of universities to concentrating considerable effort on providing students  with sufficient, concise and clear information, which is well organized into logical and understandable components, in  addition to regularly updating the content. In turn, this will increase the perceptions of usefulness and satisfaction of  the system, thereby achieving the benefits of using the e-learning system. 7. The study results can assist the universities and other institutions in recognizing that system characteristics such as, ease  of using the system, reliability of the system, personalization, integration between system components, should be  improved to make the system more reliable, user-friendly, more personalized, attractive and more intuitive, and easier  to navigate. These aspects should positively increase the perceived usefulness and satisfaction with the system. 8. This study provides universities and higher education institutes with a valid, reliable, comprehensive model and an  instrument to evaluate the success of their learning management systems. In summary, the study model introduces 11  dimensions that consider the evaluation of e-learning in all phases, from the design phase, to system usage and user  belief, to the outcome phase. This will greatly help those engaged in e-learning, in general, and LMS, in particular, to  better understand how the use of the system can be increased and how perceptions of satisfaction, usefulness, and  outcomes of the system can be improved. 8 Limitations and Recommendations for Future Studies Although respondents of the survey were students from different background, cultures, and countries, attending one of the UK  universities, the validity and reliability of the model would improve if different universities within the UK were surveyed. A  future study would also consider extending the investigation to universities in developing countries.  In addition, this study was based on students’ perceptions. Different groups of e-learning stakeholders (e.g., instructors and  administrators) could enrich the research with different points of view and provide a better understanding of the issues facing elearning systems success. On the other hand, the proposed model has explained 71.4%, 54.2%, 34.1%, and 65% of perceived satisfaction, perceived  usefulness, use, and benefits respectively of e-learning success, however, it does not fully capture the determinants of these  factors. In other words, there is approximately 29% of the variance of e-learning perceived satisfaction, 46% of the variance of  e-learning perceived usefulness, 66% of e-learning use, and 35% of e-learning benefits coming from other variables not examined  in the model.  Thus, there is still room to investigate the quality factors that determine the success of e-learning.  The EESS model proposed in this study provides researchers with the basis for future research. Researchers can explain, justify,  and compare the differences among the results. Finally, with technology and e-learning continuously evolving, longitudinal  research to examine how the e-learning quality factors revealed in this study change over time may reveal additional interesting  results. 9 References Abbas, T. (2016). Social factors affecting students’ acceptance of e-learning environments in developing and developed countries: a structural equation modeling approach. Journal of Hospitality and Tourism  Technology, 7(2), 200-212. Abdellatief, M., Sultan, A.B., Jabar, M., and Abdullah, R. (2011). A technique for quality evaluation of e-learning from developers perspective. American Journal of Economics and Business Administration, 3(1),  157-164. Abdullah, F., and Ward, R. (2016). Developing a general extended technology acceptance model for e-learning (GETAMEL) by analysing commonly used external factors. Computers in Human Behavior, 56, 238256. Alenezi, A. R., & Karim, A. (2010). An empirical investigation into the role of enjoyment, computer anxiety, computer self-efficacy and internet experience in influencing the students' intention to use e-learning:  A case study from Saudi Arabian governmental universities. Turkish Online Journal of Educational Technology-TOJET, 9(4), 22-34. Ali, A., & Ahmad, I. (2011). Key Factors for Determining Students' Satisfaction in Distance Learning Courses: A Study of Allama Iqbal Open University. Contemporary Educational Technology, 2(2). Almaiah, M. A., Jalil, M. A., & Man, M. (2016). Extending the TAM to examine the effects of quality features on mobile learning acceptance. Journal of Computers in Education, 3(4), 453-485. Almarashdeh, I. A., Sahari, N., Zin, N. A. M., and Alsmadi, M. (2010). The success of learning management system among distance learners in malaysian universities. Journal of Theoretical and Applied Information  Technology, 21(2). Al-Sabawy, A. Y., Cater-Steel, A., and Soar, J. (2013). Measuring e-learning system success (Doctoral dissertation, University of Southern Queensland). Aparicio, M., Bacao, F., and Oliveira, T. (2017). Grit in the path to e-learning success. Computers in Human Behavior, 66, 388-399. Arbaugh, J.B. (2000). Virtual classroom characteristics and student satisfaction with internet-based MBA courses. Journal of Management Education, 24(1), 32-54. Attwell, G. (2006). Evaluating E-learning: A Guide to the Evaluation of E-learning. Evaluate Europe Handbook Series, 2, 1610-0875. Awang, H., Osman, W. R. S., and Aji, Z. M. (2018). A conceptual model to evaluate virtual learning environment among Malaysian teachers. Journal of Telecommunication, Electronic and Computer Engineering  (JTEC), 10(2-4), 59-63. Bailey, J. E., and Pearson, S. W. (1983). Development of a tool for measuring and analyzing computer user satisfaction. Management Science, 29(5), 530-545. Balaban, I., Mu, E., & Divjak, B. (2013). Development of an electronic Portfolio system success model: An information systems approach. Computers & Education, 60(1), 396-411. Baroudi, J. J., and Orlikowski, W. J. (1988). A short-form measure of user information satisfaction: a psychometric evaluation and notes on use. Journal of Management Information Systems, 4(4), 44-59. Benbasat, I., and Barki, H. (2007). Quo vadis TAM? Journal of the association for information systems, 8(4), 7. Boud, D., and Prosser, M. (2002). Appraising new technologies for learning: A framework for development. Educational Media International, 39(3-4), 237-245. Journal Pre-proof    18 Chen, H. J. (2010). Linking employees’ e-learning system use to their overall job outcomes: An empirical study based on the IS success model. Computers and Education, 55(4), 1628-1639. Chen, H. R., & Tseng, H. F. (2012). Factors that influence acceptance of web-based e-learning systems for the in-service education of junior high school teachers in Taiwan. Evaluation and program planning, 35(3),  398-406. Chen, C. W. D., & Cheng, C. Y. J. (2009). Understanding consumer intention in online shopping: a respecification and validation of the DeLone and McLean model. Behaviour & Information Technology, 28(4),  335-345. Chen, W. S., and Yao, A. Y. T. (2016). An empirical evaluation of critical factors influencing learner satisfaction in blended learning: a pilot study. Universal Journal of Educational Research, 4(7), 1667-1671. Cheng, Y. M. (2011). Antecedents and consequences of e‐learning acceptance. Information Systems Journal, 21(3), 269-299. Chin, J.P., Diehl, V.A., and Norman, K.L. (1988). Development of an instrument measuring user satisfaction of the human-computer interface. Paper presented at the CHI '88 Proceedings of the SIGCHI conference  on Human factors in computing systems New York, USA. Chiu, C.M., Chiu, C.S., & Chang, H.C. (2007). Examining the integrated influence of fairness and quality on learners’ satisfaction and Web-based learning continuance intention. Information Systems Journal,  17(3), 271-287. Chuttur, M. Y. (2009). Overview of the technology acceptance model: Origins, developments and future directions. Working Papers on Information Systems, 9(37), 9-37. Cidral, W. A., Oliveira, T., Di Felice, M., and Aparicio, M. (2018). E-learning success determinants: Brazilian empirical study. Computers and Education, 122, 273-290. Cyert, R. M., and March, J. G. (1963). A behavioral theory of the firm. Englewood Cliffs, NJ, 2(4), 169-187. Dahlstrom, E., Brooks, D. C., and Bichsel, J. (2014). The current ecosystem of learning management systems in higher education: Student, faculty, and IT perspectives. Research report. Louisville, CO: ECAR.  Davis, F. D., Bagozzi, R. P., and Warshaw, P. R. (1989). User acceptance of computer technology: a comparison of two theoretical models. Management science, 35(8), 982-1003. DeLone, W. H., and McLean, E. R. (1992). Information systems success: The quest for the dependent variable. Information systems research, 3(1), 60-95. Delone, W. H., and McLean, E. R. (2003). The DeLone and McLean model of information systems success: a ten-year update. Journal of management information systems, 19(4), 9-30. Doll, W. J., and Torkzadeh, G. (1988). The measurement of end-user computing satisfaction. MIS quarterly, 259-274. Doll, W. J., Deng, X., Raghunathan, T. S., Torkzadeh, G., and Xia, W. (2004). The meaning and measurement of user satisfaction: A multigroup invariance analysis of the end-user computing satisfaction instrument.  Journal of Management Information Systems, 21(1), 227-262. Ehlers, U. D. (2004). Quality in e-learning from a learner's perspective. European Journal of Open, Distance and E-learning, 7(1). Eom, S. (2015). Effects of self-efficacy and self-regulated learning on LMS user satisfaction and LMS effectiveness. Eom, S. B., and Ashill, N. J. (2018). A system's view of e‐learning success model. Decision Sciences Journal of Innovative Education, 16(1), 42-76. Eom, S., Ashill, N. J., Arbaugh, J. B., and Stapleton, J. L. (2012). The role of information technology in e-learning systems success. Human Systems Management, 31(3-4), 147-163. Fathema, N., & Sutton, K. L. (2013). Factors influencing faculty members’ Learning Management Systems adoption behaviour: An analysis using the Technology Acceptance Model. International Journal of  Trends in Economics Management & Technology, 2(6). Fornell, C. and Cha, J. (1994). Partial least squares. In: Bagozzi, R.P. (ed.), Advanced Methods of Marketing Research. Blackwell. 52-78. Garcia-Smith, D., & Effken, J. A. (2013). Development and initial evaluation of the clinical information systems success model (CISSM). International Journal of Medical Informatics, 82(6), 539-552. Goggins, S., & Xing, W. (2016). Building models explaining student participation behavior in asynchronous online discussion. Computers & Education, 94, 241-251. Gorla, N., and Somers, T. M. (2014). The impact of IT outsourcing on information systems success. Information and Management, 51(3), 320-335. Goodhue, D. (1986). IS attitudes: Towards theoretical definition and measurement clarity. In L. Maggi, R. Zmudand J. Wetherbe (Eds), Proceedings of Seventh International Conference on Information Systems,  San Diego, Calif, 181-194. Hagos, Y., Garfield, M., & Anteneh, S. (2016, June). Measurement factors model for e-learning systems success. In Research Challenges in Information Science (RCIS), 2016 IEEE Tenth International Conference  on (pp. 1-6). IEEE. Hair, J.F., Black, W.C., Babin, B., and Anderson, R.E. (2010). Multivariate data analysis (7th ed.). New Jersey: Prentice Hall. Halawi, L. A., McCarthy, R. V., & Aronson, J. E. (2008). An empirical investigation of knowledge management systems' success. Journal of Computer Information Systems, 48(2), 121-135. Harter, S. P., and Hert, C. A. (1997). Evaluation of information retrieval systems: Approaches, issues, and methods. Annual Review of Information Science and Technology (ARIST), 32, 3-94. Hasan, M., Maarop, N., Samy, G. N., Baharum, H. I., Abidin, W. Z., & Hassan, N. H. (2017). Developing a success model of Research Information Management System for research affiliated institutions. In 2017  International Conference on Research and Innovation in Information Systems (ICRIIS) (pp. 1-6). IEEE. Hassanzadeh, A., Kanaani, F., and Elahi, S. (2012). A model for measuring e-learning systems success in universities. Expert Systems with Applications, 39(12), 10959-10966. Henseler, J., & Sarstedt, M. (2013). Goodness-of-fit indices for partial least squares path modeling. Computational Statistics, 28(2), 565-580. Henseler, J., Dijkstra, T. K., Sarstedt, M., Ringle, C. M., Diamantopoulos, A., Straub, D. W., Ketchen, D. J., Hair, J. F., Hult, G. T. M., and Calantone, R. J. (2014). Common Beliefs and Reality about Partial Least  Squares: Comments on Rönkkö & Evermann (2013), Organizational Research Methods, 17(2): 182-209. Henseler, J., Ringle, C. M., and Sarstedt, M. (2015). A new criterion for assessing discriminant validity in variance-based structural equation modeling. Journal of the academy of marketing science, 43(1), 115-135. Hou, C. K. (2012). Examining the effect of user satisfaction on system usage and individual performance with business intelligence systems: An empirical study of Taiwan's electronics industry. International  Journal of Information Management, 32(6), 560-573. Hsieh, J. J. P., & Wang, W. (2007). Explaining employee’s extended use of complex information systems. European Journal of Information Systems, 16(3), 216–227. Hsieh, J. J., & Wang, W. (2007). Explaining employees' extended use of complex information systems. European Journal of Information Systems, 16(3), 216-227. Hwang, H. G., Chang, I. C., Chen, F. J., & Wu, S. Y. (2008). Investigation of the application of KMS for diseases classifications: A study in a Taiwanese hospital. Expert Systems with Applications, 34(1), 725733. Igbaria, M., and Tan, M. (1997). The consequences of information technology acceptance on subsequent individual performance. Information and management, 32(3), 113-121. Ilias, A., AbdRazak, M.Z., Rahman, R.A., and Yasoa, M.R. (2009). End-User Computing Satisfaction (EUCS) in Computerised Accounting System (CAS): Which the Critical Factors? A Case in Malaysia. Computer  and Information Science, 2(1), P18. Ireland, J., Correia, H.M., and Griffin, T.M. (2009). Developing quality in e-learning: a framework in three parts. Quality Assurance in Education, 17(3), 250-263. Islam, A. N. (2012). Understanding e-learning system usage outcomes in hybrid courses. In 2012 45th Hawaii International Conference on System Sciences. IEEE. 118-127 Islam, A. K. M. N. (2011). The determinants of the post-adoption satisfaction of educators with an e-learning system. Journal of Information Systems Education, 22(4), 319-332. Islam, A. N. (2013). Investigating e-learning system usage outcomes in the university context. Computers & Education, 69, 387-399. Iivari, J. (2005). An empirical test of the DeLone-McLean model of information system success. ACM SIGMIS Database: the DATABASE for Advances in Information Systems, 36(2), 8-27. Ives, B., Olson, M., and Baroudi, J. J. (1983). The measurement of user information satisfaction. Communications of the ACM 26(10), 785-793. Jurison, J. (1996). The temporal nature of IS benefits: A longitudinal study. Information and management, 30(2), 75-79. Kang, Y.S., and Lee, H. (2010). Understanding the role of an IT artifact in online service continuance: An extended perspective of user satisfaction. Computers in Human Behaviour, 26(3), 353-364. Khan, B. (2005). Learning features in an open, flexible and distributed environment. AACE Journal, 13(2), 137-153. Kim, B., and Park, M. J. (2018). Effect of personal factors to use ICTs on e-learning adoption: comparison between learner and instructor in developing countries. Information Technology for Development, 24(4),  706-732. Kim, K., Trimi, S., Park, H., and Rhee, S. (2012). The impact of CMS quality on the outcomes of e‐learning systems in higher education: an empirical study. Decision Sciences Journal of Innovative Education,  10(4), 575-587. Klobas, J. E., & McGill, T. J. (2010). The role of involvement in learning management system success. Journal of Computing in Higher Education, 22(2), 114-134. Kositanurit, B., Ngwenyama, O., & Osei-Bryson, K. M. (2006). An exploration of factors that impact individual performance in an ERP environment: an analysis using multiple analytical techniques. European  Journal of Information Systems, 15(6), 556-568. Lai, C., Wang, Q., & Lei, J. (2012). What factors predict undergraduate students' use of technology for learning? A case from Hong Kong. Computers & Education, 59(2), 569-579. Landrum, H., Prybutok, V. R., and Zhang, X. (2010). The moderating effect of occupation on the perception of information services quality and success. Computers and Industrial Engineering, 58(1), 133-142. Leclercq, A. (2007). The perceptual evaluation of information systems using the construct of user satisfaction: case study of a large French group. ACM SIGMIS Database: the DATABASE for Advances in  Information Systems, 38(2), 27-60. Lee, J. K., & Lee, W. K. (2008). The relationship of e-Learner’s self-regulatory efficacy and perception of e-Learning environmental quality. Computers in Human Behavior, 24(1), 32-47. Lee, B. C., Yoon, J. O., and Lee, I. (2009). Learners’ acceptance of e-learning in South Korea: Theories and results. Computers and Education, 53(4), 1320-1329. Lee, Y. H., Hsieh, Y. C., and Hsu, C. N. (2011). Adding innovation diffusion theory to the technology acceptance model: Supporting employees' intentions to use e-learning systems. Journal of Educational  Technology and Society, 14(4). Legris, P., Ingham, J., and Collerette, P. (2003). Why do people use information technology? A critical review of the technology acceptance model. Information and management, 40(3), 191-204. Liaw, S.S. (2008). Investigating students' perceived satisfaction, behavioural intention, and effectiveness of e-learning: A case study of the Blackboard system. Computers & Education, 51(2), 864-873. Liaw, S. S., & Huang, H. M. (2013). Perceived satisfaction, perceived usefulness and interactive learning environments as predictors to self-regulation in e-learning environments. Computers & Education, 60(1),  14-24. Liaw, S. S., Huang, H. M., and Chen, G. D. (2007). Surveying instructor and learner attitudes toward e-learning. Computers and Education, 49(4), 1066-1080. Limayem, M., & Cheung, C. M. (2008). Understanding information systems continuance: The case of Internet-based learning technologies. Information & management, 45(4), 227-232. Lin, H.F. (2007). Measuring online learning systems success: Applying the updated DeLone and McLean model. Cyber Psychology and Behaviour, 10(6), 817-820.   Liu, S. H., Liao, H. L., & Peng, C. J. (2005). Applying the technology acceptance model and flow theory to online e-learning users’ acceptance behavior. E-learning, 4(H6), H8. Lwoga, E. (2014). Critical success factors for adoption of web-based learning management systems in Tanzania. International Journal of Education and Development using ICT, 10(1). MacDonald, C. J., Stodel, E. J., Farres, L. G., Breithaupt, K., and Gabriel, M. A. (2001). The demand-driven learning model: A framework for web-based learning. The Internet and Higher Education, 4(1), 9-30. MacDonald, C.J., and Thompson, T.L. (2005). Structure, content, delivery, service, and outcomes: Quality e-learning in higher education. The International Review of Research in Open and Distance Learning,  6(2), 1-25. Marjanovic, U., Delić, M., and Lalic, B. (2016). Developing a model to assess the success of e-learning systems: evidence from a manufacturing company in transitional economy. Information Systems and eBusiness Management, 14(2), 253-272. Massy, J. (2002). Quality and elearning in Europe. Summary Report 2002. UK: Bizmedia. McGill, T. J., and Klobas, J. E. (2009). A task–technology fit view of learning management system impact. Computers and Education, 52(2), 496-508. Mohammadi, H. (2015). Investigating users’ perspectives on e-learning: An integration of TAM and IS success model. Computers in Human Behavior, 45, 359-374. Motaghian, H., Hassanzadeh, A., and Moghadam, D. K. (2013). Factors affecting university instructors' adoption of web-based learning systems: Case study of Iran. Computers and Education, 61, 158-167. Mtebe, J. S., and Raphael, C. (2018). Key factors in learners' satisfaction with the e-learning system at the University of Dar es Salaam, Tanzania. Australasian Journal of Educational Technology, 34(4). Ngai, E. W., Poon, J. K. L., & Chan, Y. H. (2007). Empirical examination of the adoption of WebCT using TAM. Computers & education, 48(2), 250-267. Nair, P. K., Ali, F., and Leong, L. C. (2015). Factors affecting acceptance and use of ReWIND: Validating the extended unified theory of acceptance and use of technology. Interactive Technology and Smart  Education, 12(3), 183-201. Navimipour, N. J., and Zareie, B. (2015). A model for assessing the impact of e-learning systems on employees’ satisfaction. Computers in Human Behavior, 53, 475-485. Oliver, R. (2005). Quality assurance and e-learning: blue skies and pragmatism. ALT-J, 13(3), 173-187. Ong, C. S., and Lai, J. Y. (2007). Measuring user satisfaction with knowledge management systems: scale development, purification, and initial test. Computers in Human Behavior, 23(3), 1329-1346. Ong, C. S., Lai, J. Y., & Wang, Y. S. (2004). Factors affecting engineers’ acceptance of asynchronous e-learning systems in high-tech companies. Information & management, 41(6), 795-804. Ozkan, S., and Koseler, R. (2009). Multi-dimensional students’ evaluation of e-learning systems in the higher education context: An empirical investigation. Computers and Education, 53(4), 1285-1296. Park, S. Y. (2009). An analysis of the technology acceptance model in understanding university students' behavioral intention to use e-learning. Educational technology & society, 12(3), 150-162. Journal Pre-proof    19 Park, S., Zo, H., Ciganek, A. P., & Lim, G. G. (2011). Examining success factors in the adoption of digital object identifier systems. Electronic commerce research and applications, 10(6), 626-636. Petter, S., DeLone, W., and McLean, E. (2008). Measuring information systems success: models, dimensions, measures, and interrelationships. European journal of information systems, 17(3), 236-263. Pituch, K. A., and Lee, Y. K. (2006). The influence of system characteristics on e-learning use. Computers and Education, 47(2), 222-244. Rai, A., Lang, S. S., and Welker, R. B. (2002). Assessing the validity of IS success models: An empirical test and theoretical analysis. Information systems research, 13(1), 50-69. Remenyi, D., and Money, A. (1991). A user-satisfaction approach to IS effectiveness measurement. Journal of Information Technology, 6(3-4), 162-175. Roca, J. C., and Gagné, M. (2008). Understanding e-learning continuance intention in the workplace: A self-determination theory perspective. Computers in human behavior, 24(4), 1585-1604. Sabherwal, R., Jeyaraj, A., & Chowa, C. (2006). Information system success: individual and organizational determinants. Management science, 52(12), 1849-1864. Sánchez, R. A., and Hueros, A. D. (2010). Motivational factors that influence the acceptance of Moodle using TAM. Computers in human behavior, 26(6), 1632-1640. Sandjojo, N., and Wahyuningrum, T. (2015). Measuring e-learning systems success: Implementing D and M is success model. In Interactive Digital Media (ICIDM), 4th International Conference on (pp. 1-6). IEEE. Seddon, P. B. (1997). A respecification and extension of the DeLone and McLean model of IS success. Information systems research, 8(3), 240-253. Seddon, P.B., and Kiew, M.Y. (1994). A partial test and development of the DeLone and McLean model of IS success. Australian Journal of Information Systems, 4(1), 99-110. Selim, H. M. (2007). Critical success factors for e-learning acceptance: Confirmatory factor models. Computers and Education, 49(2), 396-413. Seta, H. B., Wati, T., Muliawati, A., and Hidayanto, A. N. (2018). E-Learning Success Model: An Extension of DeLone and McLean IS Success Model. Indonesian Journal of Electrical Engineering and Informatics  (IJEEI), 6(3), 281-291. Somers, T.M., Nelson, K., and Karimi, J. (2003). Confirmatory Factor Analysis of the End User Computing Satisfaction Instrument: Replication within an ERP Domain. Decision Sciences, 34(3), 595-621. ŠUmak, B., HeričKo, M., and PušNik, M. (2011). A meta-analysis of e-learning technology acceptance: The role of user types and e-learning technology types. Computers in Human Behavior, 27(6), 2067-2077. Sun, P.C., Tsai, R.J., Finger, G., Chen, Y.Y., and Yeh, D. (2008). What drives a successful e-Learning? An empirical investigation of the critical factors influencing learner satisfaction. Computers and Education,  50(4), 1183-1202. Surendran, P. (2012). Technology acceptance model: A survey of literature. International Journal of Business and Social Research, 2(4), 175-178. Taylor, S., and Todd, P. (1995). Assessing IT usage: The role of prior experience. MIS Quarterly, 19(4), 561-570. Tenenhaus, M., Vinzi, V. E., Chatelin, Y. M., & Lauro, C. (2005). PLS path modeling. Computational statistics & data analysis, 48(1), 159-205. Teo, T., Zhou, M., Fan, A. C. W., and Huang, F. (2019). Factors that influence university students’ intention to use Moodle: a study in Macau. Educational Technology Research and Development, 1-18. Thong, J. Y., and Yap, C. S. (1996). Information systems effectiveness: A user satisfaction approach. Information Processing and Management, 32(5), 601-610. Urbach, N., and Ahlemann, F. (2010). Structural equation modeling in information systems research using partial least squares. Journal of Information technology theory and application, 11(2), 5-40. Üstünel, H. H. (2016). The Influence of Critical Factors on E-Learning Satisfaction. Başkent University Journal of Education, 3(2), 99-123. Van Raaij, E. M., & Schepers, J. J. (2008). The acceptance and use of a virtual learning environment in China. Computers & Education, 50(3), 838-852. Venkatesh, V., and Bala, H. (2008). Technology acceptance model 3 and a research agenda on interventions. Decision Sciences, 39(2), 273-315. Venkatesh, V., and Davis, F. D. (2000). A theoretical extension of the technology acceptance model: Four longitudinal field studies. Management science, 46(2), 186-204. Venkatesh, V., Thong, J. Y., and Xu, X. (2012). Consumer acceptance and use of information technology: extending the unified theory of acceptance and use of technology. MIS quarterly, 36(1), 157-178. Walker, S. L., and Fraser, B. J. (2005). Development and validation of an instrument for assessing distance education learning environments in higher education: The Distance Education Learning Environments  Survey (DELES). Learning Environments Research, 8(3), 289-308. Wahab, A. G. (2008). Modeling Students’ Intention to Adopt E‐learning: A Case from Egypt. The Electronic Journal of Information Systems in Developing Countries, 34(1), 1-13. Wang, Y. S. (2003). Assessment of learner satisfaction with asynchronous electronic learning systems. Information & Management, 41(1), 75-86. Wang, H. C., and Chiu, Y. F. (2011). Assessing e-learning 2.0 system success. Computers and Education, 57(2), 1790-1800. Wang, Y. S., and Liao, Y. W. (2007). The conceptualization and measurement of m-commerce user satisfaction. Computers in human behavior, 23(1), 381-398. Wang, Y. S., and Liao, Y. W. (2008). Assessing eGovernment systems success: A validation of the DeLone and McLean model of information systems success. Government Information Quarterly, 25(4), 717-733. Wixom, B. H., and Todd, P. A. (2005). A theoretical integration of user satisfaction and technology acceptance. Information systems research, 16(1), 85-102. Wu, J. H., Tennyson, R. D., and Hsia, T. L. (2010). A study of student satisfaction in a blended e-learning system environment. Computers and Education, 55(1), 155-16. Wu, J. H., & Wang, Y. M. (2006). Measuring KMS success: A respecification of the DeLone and McLean's model. Information & Management, 43(6), 728-739. Xing, W., Kim, S. M., & Goggins, S. (2015). Modeling performance in asynchronous CSCL: an exploration of social ability, collective efficacy and social interaction. International Society of the Learning Sciences,  Inc.[ISLS].. Zaidi, S. F. H., Siva, S., and Marir, F. (2014). Development and validation of a framework for assessing the performance and trust in e-government services. Development, 7(4), 28-37. Zhao, Y., Bandyopadhyay, K., and Bandyopadhyay, S. (2019, January). What matters most in online sap-enabled course learning? A system view of determinants. In Proceedings of the 52nd Hawaii International  Conference on System Sciences. Zhu, K., & Kraemer, K. L. (2005). Post-adoption variations in usage and value of e-business by organizations: cross-country evidence from the retail industry. Information systems research, 16(1), 61-84. Journal Pre-proof    20 Appendix 1: Measure Aspect Code Related studies Technical System Quality 1. It is easy to use Moodle Ease of use TSQ1 Sedara et al. (2004); Davis (1989); DeLone & McLean (2003) 2. It is easy to understand the structure of Moodle and how to use it Ease to learn TSQ2 Sedara et al. (2004); DeLone & McLean (2003) 3. Moodle meets my requirements and I can find the information I need User requirements TSQ3 Sedara et al. (2004) 4. Moodle includes the necessary features and functions I need System features TSQ4 Sedara et al. (2004) 5. Moodle is always available for me to perform learning activities System availability TSQ5 DeLone & McLean (2003) 6. Moodle is flexible to interact with Flexibility TSQ6 Sedara et al. (2004); Selim (2003) 7. All components within Moodle are fully integrated and consistent Integration  TSQ7 Sedara et al. (2004); Selim (2003) 8. Moodle launches and runs right away System reliability TSQ8 Sedara et al. (2004); DeLone & McLean (2003) 9. Moodle does not crash frequently Fulfilment  TSQ9 Sedara et al. (2004) 10. Moodle protects my information from unauthorized access by logging only with  my account and password Security TSQ10 Holsapple & Lee-Post (2006) 11. Moodle provides me with a personalised entry page (e.g. showing my modules,  recommending additional modules and courses) Personalization TSQ11 DeLone & McLean (2003); Ozkan & Koseler (2009) Information Quality 12. Moodle has provided me with sufficient and required information Sufficiency  INQ1 DeLone & McLean (2003) 13. Information and resources needed from Moodle are always accessible Accessibility INQ2 Ozkan & Koseler (2009); Selim (2003) 14. Information from Moodle is in a form that is readily usable Usability  INQ3 Ozkan & Koseler (2009); Sedera and Gable (2004) 15. Information in Moodle is concise and clear Conciseness  INQ4 Sedara et al. (2004) 16. The structure of Moodle is well organized into logical and understandable  components Understandability INQ5 Sedara et al. (2004); Selim (2003) 17. The content of Moodle is up to date Up to date content INQ6 Ozkan & Koseler, 2009 18. I perceive the design of Moodle (e.g. fonts, style, colour, images, videos) to be  good and meets the quality standards Content design quality INQ7 Roca et al. (2006); Service Quality 19. There are enough and clear instructions/training about how to use Moodle Providing guidance  services SRQ1 Hassazadeh et al. (2012); Chang & King (2005) 20. Moodle provides proper online assistance and help Providing help SRQ2 Holsapple & Lee-Post (2006); Ozkan & Koseler (2009) 21. The IT services staff is available and cooperative when facing an error at Moodle Staff Availability SRQ3 Holsapple & Lee-Post (2006) 22. The IT services staff understands the specific needs of students Fair understanding  SRQ4 DeLone & McLean (2003); Holsapple & Lee-Post (2006) 23. I receive a satisfactory and timely response from the IT services staff Responsiveness  SRQ5 DeLone &McLean (2003) Educational System Quality 24. Moodle provides interactivity and communication facilities such as chat, forums,  and announcements. Interactivity and  communication ESQ1 Hassanzadeh et al. (2012); Sun et al. (2008); Selim (2003) 25. I believe that communication facilities have been effective  learning components  in my study Effective  communication ESQ2 Hassanzadeh et al. (2012); Sun et al. (2008); Selim (2003) 26. Moodle provides me with different learning styles (e.g. flash animation, video,  audio, text, simulation, etc.) and they are interesting and appropriate in my study Diversity of learning  styles ESQ3 Hassanzadeh et al. (2012); Sun et al. (2008); Selim (2003) 27. Moodle provides evaluation components and assessment materials (e.g., quizzes,  assignments) Evaluation components ESQ4 Hassanzadeh et al. (2012); Sun et al. (2008); Selim (2003) Support System Quality 28. Moodle provides appropriate information about plagiarism issues when  submitting assignments through the system, Ethical issues SUP1 Khan (2005); Ozkan & Koseler (2009) 29. Moodle provides information about behavioural considerations when  communicating with students or with instructors Behavioral  considerations SUP2 Khan (2005); Ozkan & Koseler (2009) 30. Moodle provides information about the accessibility of content, permission for  viewing course materials, and any other personal data in the system Legal issues SUP3 Khan (2005); Ozkan & Koseler (2009) 31. If it is optional, I would still prefer to use Moodle as a supportive tool in the  module Promotion of the  e-learning system SUP4 Ozkan & Koseler (2009) Learner Quality 32. I believe it is good to use Moodle Learner’s behaviour  LER1 Davis (1989) 33. I have a positive attitude toward using Moodle Learner’s attitude LER2 Davis (1989); Sun et al. (2008) 34. I am not intimidated by using Moodle Learner’s anxiety LER3 Sun et al. (2008); Piccoli et al. (2001) 35. My previous experience with e-learning systems and computer applications  helped me in using Moodle Learner’s previous  experience LER4 Ozkan & Koseler (2009); Selim (2007) 36. I am able to perform tasks in Moodle successfully Learner’s self-efficacy LER5 Roca et al. (2006); Sun et al. (2008) Instructor Quality 37. I use Moodle as recommended by my instructors Subjective norm  INS1 Roca et al. (2006) 38. I think an instructor’s enthusiasm about using Moodle stimulates my desire to  learn Instructor’s enthusiasm INS2 Sun et al. (2008) 39. I receive a prompt response to questions and concerns from my instructors in  Moodle Instructor’s  responsiveness INS3 Sun et al. (2008); Ozkan & Koseler (2009) 40. I think communicating and interacting with  instructors are important and  valuable in Moodle Instructor’s interactive  communication INS4 Sun et al. (2008); Ozkan & Koseler (2009) 41. Generally, my instructors have a positive attitude to the utilization of Moodle Instructor’s attitude INS5 Sun et al. (2008); Lee et al. (2009) Perceived Satisfaction 42. I am satisfied with the performance of Moodle Satisfaction with system  performance SAT1 Arbaugh (2000); Hassanzadeh et al. (2012) 43. I enjoy using Moodle in my study Enjoyable experience  SAT2 Arbaugh (2000) 44. Moodle satisfies my educational needs Providing educational  needs SAT3 Hassanzadeh et al. (2012) 45. Overall, I am pleased with the experience of using Moodle Overall satisfaction SAT4 Cidral et al. (2018) Perceived Usefulness 46. Using Moodle enables me to accomplish my tasks more quickly Accomplishing tasks  quickly USF1 Selim (2003); Venkatesh and Davis (2000) and Pituch and Lee  (2006); Rai et al. (2002) 47. Using Moodle improves my learning performance Improving learning  performance USF2 Selim (2003); Roca et al. (2006); Rai et al. (2002) 48. Using Moodle helps me learn effectively Effective learning  USF3 Venkatesh and Davis (2000) and Pituch and Lee (2006); Roca et al.  (2006); Selim (2003) 49. Overall Moodle is useful Overall usefulness  USF4 Roca et al. (2006); Selim (2003) Use 50. I use Moodle frequently Frequency of use  USE1 DeLone & McLean (2003); Selim (2003) 51. I depend on Moodle in my study Dependence on system USE2 DeLone & McLean (2003); Selim (2003); Rai et al. (2002) 52. I use Moodle regularly Regular use USE3 DeLone & McLean (2003); Selim (2003) 53. On average, I spend a long time on using Moodle Duration of use USE4 DeLone & McLean (2003); Selim (2003) Benefits  54. Using Moodle has increased my knowledge and helped me to be successful in  the module Increasing knowledge BNT1 Hassanzadeh et al. (2012) 55. Moodle is a very effective educational tool and has helped me to improve my  learning process Improving learning  process BNT2 Hassanzadeh et al. (2012); Holsapple & LeePost (2006); Rai et al.  (2002) 56. Moodle makes communication easier with the instructor and other classmates Easier interaction and  communication BNT3 Almutairi & Subramanian (2005); Selim (2003) 57. Moodle saves my time in searching for materials and cuts down expenditure such  as paper cost Time and cost saving BNT4 DeLone & McLean (2003); Holsapple & LeePost (2006);  Hassanzadeh et al. (2012) 58. Moodle has helped me to achieve the learning goals of the module Achieving learning goals BNT5 Hassanzadeh et al. (2012); Selim (2003) Journal Pre-proof    21 Appendix 2: Cross Loadings BNT ESQ INQ INS LER SAT SRQ SUP TSQ USE USF BNT1 0.840 0.300 0.430 0.490 0.550 0.600 0.260 0.390 0.420 0.430 0.620 BNT2 0.870 0.330 0.570 0.510 0.670 0.710 0.330 0.420 0.520 0.440 0.690 BNT4 0.770 0.210 0.410 0.410 0.480 0.530 0.220 0.380 0.410 0.310 0.530 BNT5 0.840 0.300 0.450 0.460 0.570 0.600 0.240 0.450 0.460 0.410 0.650 ESQ1 0.320 0.850 0.330 0.300 0.300 0.330 0.180 0.370 0.300 0.270 0.320 ESQ2 0.120 0.510 0.130 0.250 0.130 0.120 -0.040 0.040 0.160 0.060 0.100 ESQ3 0.110 0.550 0.130 0.150 0.120 0.100 -0.030 0.070 0.100 0.130 0.070 ESQ4 0.320 0.880 0.350 0.330 0.290 0.290 0.140 0.360 0.280 0.300 0.270 INQ1 0.470 0.340 0.730 0.340 0.530 0.530 0.280 0.400 0.520 0.330 0.450 INQ2 0.390 0.220 0.720 0.280 0.460 0.450 0.280 0.310 0.490 0.210 0.390 INQ3 0.450 0.260 0.820 0.370 0.550 0.570 0.340 0.350 0.570 0.260 0.470 INQ4 0.480 0.270 0.840 0.360 0.580 0.570 0.360 0.340 0.630 0.250 0.500 INQ5 0.410 0.280 0.780 0.350 0.500 0.520 0.380 0.290 0.580 0.240 0.420 INQ6 0.320 0.270 0.650 0.320 0.370 0.420 0.290 0.240 0.490 0.170 0.360 INQ7 0.390 0.290 0.650 0.260 0.430 0.480 0.310 0.260 0.460 0.290 0.430 INS1 0.430 0.290 0.360 0.630 0.430 0.450 0.230 0.290 0.380 0.230 0.390 INS2 0.340 0.160 0.230 0.690 0.340 0.330 0.200 0.290 0.240 0.140 0.320 INS3 0.460 0.330 0.350 0.840 0.420 0.380 0.200 0.290 0.340 0.280 0.350 INS4 0.250 0.200 0.170 0.570 0.270 0.200 0.090 0.090 0.210 0.090 0.200 INS5 0.440 0.280 0.370 0.780 0.420 0.410 0.260 0.290 0.380 0.210 0.400 LER1 0.670 0.300 0.570 0.490 0.880 0.710 0.330 0.530 0.540 0.460 0.690 LER2 0.620 0.280 0.640 0.500 0.890 0.770 0.350 0.460 0.600 0.410 0.670 LER3 0.480 0.270 0.540 0.370 0.800 0.600 0.210 0.380 0.500 0.360 0.460 LER4 0.290 0.110 0.220 0.290 0.460 0.270 0.220 0.210 0.190 0.160 0.260 LER5 0.550 0.280 0.530 0.460 0.820 0.590 0.250 0.400 0.490 0.360 0.510 SAT1 0.570 0.280 0.540 0.400 0.630 0.820 0.340 0.430 0.460 0.370 0.550 SAT2 0.650 0.280 0.610 0.490 0.690 0.890 0.390 0.410 0.560 0.400 0.640 SAT3 0.670 0.310 0.600 0.460 0.670 0.880 0.380 0.440 0.570 0.460 0.660 SAT4 0.680 0.300 0.650 0.480 0.750 0.920 0.350 0.430 0.600 0.370 0.680 SRQ1 0.250 0.090 0.340 0.220 0.290 0.330 0.760 0.300 0.280 0.150 0.280 SRQ2 0.290 0.120 0.360 0.190 0.280 0.340 0.810 0.280 0.350 0.140 0.290 SRQ3 0.300 0.110 0.380 0.250 0.320 0.360 0.900 0.270 0.380 0.120 0.280 SRQ4 0.220 0.110 0.330 0.270 0.250 0.330 0.800 0.210 0.330 0.100 0.230 SRQ5 0.200 0.140 0.310 0.220 0.240 0.270 0.680 0.170 0.270 0.080 0.170 SUP1 0.250 0.280 0.200 0.240 0.250 0.190 0.160 0.700 0.140 0.180 0.220 SUP2 0.280 0.210 0.210 0.230 0.240 0.230 0.260 0.750 0.200 0.130 0.230 SUP3 0.330 0.230 0.260 0.260 0.300 0.280 0.300 0.790 0.210 0.160 0.300 SUP4 0.500 0.340 0.450 0.340 0.570 0.550 0.240 0.800 0.390 0.430 0.570 TSQ1 0.510 0.240 0.550 0.370 0.590 0.560 0.260 0.330 0.800 0.360 0.500 TSQ3 0.420 0.290 0.570 0.330 0.490 0.450 0.270 0.240 0.800 0.290 0.390 TSQ4 0.430 0.200 0.570 0.390 0.460 0.450 0.300 0.260 0.770 0.240 0.420 TSQ6 0.370 0.290 0.540 0.340 0.420 0.470 0.380 0.280 0.750 0.190 0.360 TSQ7 0.330 0.230 0.540 0.300 0.390 0.450 0.380 0.270 0.700 0.130 0.370 USE1 0.400 0.320 0.330 0.240 0.420 0.410 0.150 0.330 0.300 0.890 0.460 USE2 0.450 0.260 0.330 0.240 0.440 0.440 0.140 0.310 0.310 0.920 0.540 USE3 0.430 0.280 0.300 0.220 0.420 0.400 0.120 0.300 0.290 0.930 0.490 USE4 0.430 0.230 0.250 0.320 0.370 0.370 0.140 0.330 0.260 0.800 0.460 USF1 0.640 0.280 0.500 0.410 0.570 0.640 0.330 0.480 0.490 0.470 0.850 USF2 0.680 0.270 0.470 0.420 0.580 0.620 0.270 0.440 0.430 0.500 0.910 USF3 0.680 0.260 0.480 0.440 0.570 0.600 0.280 0.440 0.450 0.470 0.900 USF4 0.640 0.290 0.590 0.440 0.680 0.670 0.250 0.430 0.520 0.470 0.830 Journal Pre-proof    22 Appendix 3: Results Summary of the Measurement Model Reliability Validity Indicator Reliability Internal Consistency Reliability Convergent  Validity Discriminant  Validity Factor Loadings Cronbach’s  Alpha Composite  Reliability CR AVE HTMT Latent  Variable Indicators Loading ≥ 0.70 or > 0.40 & has no  impact on AVE and CR α ≥ 0.70 CR ≥ 0.70  AVE ≥ 0.50 HTMT ≤ 0.90 TSQ1 0.800 TSQ3 0.802 TSQ4 0.771 TSQ6 0.754 TSQ TSQ7 0.704 0.830 0.880 0.590 Yes INQ1 0.731 INQ2 0.717 INQ3 0.820 INQ4 0.839 INQ5 0.781 INQ6 0.653 INQ INQ7 0.647 0.860 0.900 0.550 Yes SRQ1 0.759 SRQ2 0.808 SRQ3 0.899 SRQ4 0.796 SRQ SRQ5 0.677 0.850 0.890 0.630 Yes ESQ1 0.850 ESQ2 0.512 ESQ3 0.553 ESQ ESQ4 0.878 0.710 0.800 0.520 Yes SUP1 0.700 SUP2 0.748 SUP3 0.789 SUP SUP4 0.800 0.800 0.850 0.580 Yes LER1 0.882 LER2 0.894 LER3 0.796 LER4 0.457 LER LER5 0.823 0.840 0.890 0.620 Yes INS1 0.631 INS2 0.686 INS3 0.842 INS4 0.573 INS INS5 0.780 0.750 0.830 0.510 Yes SAT1 0.824 SAT2 0.886 SAT3 0.877 SAT SAT4 0.919 0.900 0.930 0.770 Yes USF1 0.854 USF2 0.910 USF3 0.900 USF USF4 0.832 0.900 0.930 0.770 Yes USE1 0.890 USE2 0.918 USE3 0.929 USE USE4 0.802 0.910 0.940 0.790 Yes BNT1 0.843 BNT2 0.871 BNT3 0.771 BNT BNT5 0.840 0.850 0.900 0.690 Yes  Journal Pre-proof    The research article “Evaluating E-learning Systems Success: An Empirical Study” highlights are the  following.  Study on evaluating e-learning systems success in one of the UK universities  Four approaches for evaluating e-learning systems success  A comprehensive model based on DeLone & McLean IS model, TAM, e-learning satisfaction  models and e-learning quality models  Seven quality factors are success determinants:  system, information, service, educational,  support, learner, and instructor  Determinants of e-learning benefits are: perceived usefulness, perceived satisfaction, and use 