1SEG-MAT: 3D Shape Segmentation Using Medial Axis TransformCheng Lin, Lingjie Liu, Changjian Li, Leif Kobbelt, Bin Wang, Shiqing Xin, Wenping WangAbstract—Segmenting arbitrary 3D objects into constituent parts that are structurally meaningful is a fundamental problem encountered in a wide range of computer graphics applications. Existing methods for 3D shape segmentation suffer from complex geometry processing and heavy computation caused by using low-level features and fragmented segmentation results due to the lack of global consideration. We present an efﬁcient method, called SEG-MAT, based on the medial axis transform (MAT) of the input shape. Speciﬁcally, with the rich geometrical and structural information encoded in the MAT, we are able to develop a simple and principled approach to effectively identify the various types of junctions between different parts of a 3D shape. Extensive evaluations and comparisons show that our method outperforms the state-of-the-art methods in terms of segmentation quality and is also one order of magnitude faster.Index Terms—Shape Analysis, Shape Segmentation, Medial Axis Transform, Geometry!1 INTRODUCTION AUtomatically segmenting 3D shapes into structurally simple parts is an important problem in many applications of computer graphics and computer vision. Most existing methods can be roughly categorized into two classes based on their goals and techniques. The ﬁrst class of methods is based on supervised learning and relies on annotated semantic labels. Basically, the semantic meanings are pre-deﬁned consistently within a shape category, and then the semantic labels are manually annotated on datasets to train the neural networks. The second class of methods uses geometrical analysis and can be either rule-based or unsupervised learning-based. These methods decompose a shape by ﬁnding part boundaries where certain geometrical properties are met. Semantic 1 and geometrical segmentation methods have different criteria and goals. The semantic segmentation methods aim to ﬁnd the correspondences between shapes and pre-deﬁned labels, but do not focus on the part instances; the geometrical segmentation methods predominantly follow the minima rule [1], that is, each part should be weakly convex, which is shown in Fig. 1. These methods also have different technical merits and applications in different problem settings. The semantic methods are used to repeatedly identify semantic meanings for a group of similar shapes in the same category, while handling a unique shape or an unseen category is out of its scope; the geometrical methods are not limited to pre-deﬁned labels or• C. Lin, L. Liu, C. Li and W. Wang are with The University of Hong Kong. E-mail: chlin@hku.hk, liulingjie0206@gmail.com, chjili2011@gmail.com, wenping@cs.hku.hk• L. Kobbelt is with RWTH Aachen University. E-mail: kobbelt@cs.rwthaachen.de• B. Wang is with Tsinghua University and Beijing National Research Center for Information Science and Technology (BNRist). E-mail: wangbins@tsinghua.edu.cn• S. Xin is with Shandong University. E-mail: xinshiqing@gmail.com1. The“semantic” and “geometrical” methods refer to the techniques used, i.e., learning from semantic labels or analyzing geometrical properties.SEG-MAT (geometrical analysis) ShapePFCN [2] (semantic learning)Fig. 1. Difference between geometrical and semantic segmentation methods. The geometrical methods segment a shape into part instances and usually produce weakly convex components; the semantic learning methods focus on the correspondences between the pre-deﬁned labels and shapes without considering detailed part instances.Fig. 2. Our algorithm is a geometry-driven method for single shape segmentation and analysis.categories, but they cannot give the interpretable semantic labels of the parts. In this paper, we return to the classic method based on the geometrical analysis for segmenting an arbitrary 3D shape (see Fig. 2). 3D shape segmentation driven by geometrical analysis can be used to guide various tasks including modeling [3], [4], retrieval [5], [6], mesh multiresolution and compression [7], texture mapping [8], reverse engineering [9], etc. Also, a robust geometry-based shape segmentation method can facilitate the data annotation process of various data-driven methods for 3D shape analysis. Although shape segmentation by geometrical analysis is a well-researched problem, existing methods still have some notable issues. (i) A desirable part may have complexarXiv:2010.11488v1  [cs.GR]  22 Oct 20202geometry and varying properties. Therefore, the methods using a single feature descriptor struggle to characterize the geometry of a part [10], while extracting various features to encode low-level geometrical properties needs complex optimizations and a large quantity of computation time [11], [12]. (ii) The extracted local geometrical features lack highlevel structure information of shape context, which tends to give counter-intuitive segmentation results. (iii) Many approaches need to tune shape-speciﬁc parameters, such as indicating the number of parts to perform a clustering algorithm for different shapes or categories [13], which creates a burden on users.(a) (b)radiussurfacemedial axismaximal sphereFig. 3. Illustration of the medial axis transform (MAT). (a) The MAT of a 2D shape consists of a set of centers of the maximal inscribed circles together with the circle radii. (b) In 3D, the MAT consists of a set of centers of the maximal inscribed spheres of a shape together with the sphere radii.We propose a new method based on the medial axis transform (MAT) [14] for 3D shape segmentation. An illustration of the MAT of a 2D and a 3D shape is shown in Fig. 3. Our key observation is that the MAT of a 3D shape encodes rich structural and geometrical information, which provides valuable clues for robust 3D shape segmentation. Instead of extracting low-level features, we propose to use the MAT to analyze high-level junctions where different parts of a 3D shape meet. As a result, our method overcomes the aforementioned limitations of existing methods. First, the MAT is already a compact shape representation in which a series of geometrical clues are aggregated, such as thickness, angles and branches; therefore, it can characterize the geometrical variation jointly from different perspectives, which overcomes the issue (i). Second, the MAT is globally informative which is reﬂected in two aspects: (1) it extracts the global structure of a shape; (2) since the MAT is a volume-based representation, segmenting the MAT is to handle volumetrical parts rather than local surface points. Thus, the global information is signiﬁcantly reinforced in the shape analysis, which overcomes the issue (ii). Third, our method focuses on ﬁnding the high-level junctions instead of clustering low-level feature descriptors, enabling a simple but effective formulation without complex optimization and heavy computation; this overcomes the issues (i) and (iii). We will present experimental results later in the paper to demonstrate the improvements over the other existing methods. To summarize, our proposed method has the following strengths and contributions:• Our method is effective and simple. It outperforms the state-of-the-art methods on public datasets andis about one order of magnitude faster. Our method is also ﬂexible and robust; it can generate reasonable segmentation results for different datasets and categories using the same set of parameters.• We propose a novel formulation on the MAT for shape analysis. We make full use of its advantages to exploit the structural and geometrical information encoded, while circumventing its drawback, i.e., the notorious instability of MAT.2 RELATED WORK2.1 3D shape segmentationIn the past decades, numerous works have been developed for 3D shape segmentation. The different categories of methods are discussed in detail below. Readers can also refer to [15] for a comprehensive survey. Supervised learning by semantic labels. This kind of methods [2], [16], [17], [18] is learning-based, which aims to label an input shape with a set of pre-deﬁned semantic meanings. With strong supervision, these methods are able to provide superior results with useful semantic labels. However, the limitations of these methods lie in the requirement of a large amount of manually labeled segmentation results. Also, the trained neural network can only be used to segment the shapes in the same category with the same semantic components, which limits their applicability to some extent. Note that methods of this kind have different goals, applications and technical merits with our method; therefore, we do not directly compare our method with them but give insightful discussions in Sec. 5.2. Rule-based segmentation by geometrical analysis. Our method falls into this class. These methods aim to ﬁnd the geometrical boundaries between parts where some geometrical properties are met, without considering explicit semantics labels or consistency across shapes. These methods usually extract certain feature descriptors on the surface of a shape for segmentation, such as weakly convex decomposition [12], [19], concavity-aware ﬁelds [20], randomized cuts [13], random walks [21], core extraction [22] and K-Means [23]. The development of these methods is predominantly guided by the minima rule [1], which indicates that a complex shape is a composition of approximately convex parts and the cut boundaries lie along the concavities. These methods are normally validated and compared using the Princeton Segmentation Benchmark (PSB) [24]. The evaluations on the PSB show that our method outperforms the state-of-the-art methods and is about one order of magnitude faster. Unsupervised learning by geometrical analysis. In recent years, there has been a growing interest in unsupervised learning for geometrical segmentation. This kind of methods also targets discovering a shape’s intrinsic geometry instead of pre-deﬁned labels, but they resort to learning from large amounts of data. Shu et al. [11] propose to transform a set of handcrafted features using an auto-encoder and then segment the shape into different parts without any predeﬁned labels. Tulsiani et al. [25] propose an unsupervised method to generate a primitive-based representation to approximate a target 3D shape. Each part is represented by a cuboid and the network is trained using a reconstruction3loss. Sun et al. [26] present an adaptive hierarchical cuboid representation for 3D shape abstraction. These methods all need to be trained separately on each shape category. In addition, cuboids cannot represent complex geometry, causing the difﬁculty of handling complex structures and shape details. Our method, however, is able to handle arbitrary 3D shapes using consistent settings without the need for training data. We compare our method with them and show better performance in terms of segmentation quality and ﬂexibility (see Sec. 5.2). Co-segmentation methods. Co-segmentation is a speciﬁc instance of shape segmentation problem. These methods [11], [27], [28] take as input a collection of shapes that have some common characteristics and output consistent segmentation results across shapes. More recently, Chen et al. introduce BAE-NET [29], a branched autoencoder network for shape co-segmentation. These methods ensure the consistency of the segmentation across shapes within the same category, but cannot handle a single shape.2.2 Interior information for structure analysisSkeletal representations. The closely relevant methods to SEG-MAT are those based on curve skeletons [30], [31], [32]. These methods exploit the simplicity and componentwise structure of the shape skeletons to produce reasonable segmentation results. However, the curve skeletons are only empirically understood for tube-like parts but not mathematically deﬁned for arbitrary shapes. Therefore, only articulated shapes can be properly represented by curve skeletons, and these methods can only be applied to a special class of shapes. In contrast, SEG-MAT overcomes this limitation by using the MAT which is rigorously deﬁned as a complete representation for an arbitrary 3D shape. Feng et al. [33] analyze the cut distribution based on the medial geodesic function [34] (MGF) computed with the medial surfaces to identify different parts for shape segmentation. The method solely relies on the single descriptor MGF without considering the shape structure; while SEG-MAT leverages various properties of the MAT, leading to higherquality and more structure-aware segmentation results. Volumetric representations. There are a few methods that use the volumetric information for shape segmentation, such as bounding volume computation [35], part-aware metric [36] and lines-of-sight [19]. Zhou et al. propose a quantitative measure of cylindricity for a shape part, enabling a shape decomposition method using generalized cylinders (GCD). In nature, the GCD is still based on the simplicity of curve skeletons so it inevitably exhibits the common limitations when applied to some non-tubular shapes. Shapira et al. [10] introduce shape diameter function (SDF) for 3D shape segmentation. The SDF is used as an alternative to MAT for estimating the local thickness of an object, since existing techniques cannot handle the instability of MAT. In contrast, we directly use the MAT since our novel and simple formulations can address this problem. Our method also signiﬁcantly outperforms the SDF method since the MAT is more structurally informative.2.3 Region growing for 3D segmentationThe region growing technique is widely used for segmentation due to its simplicity. The super-face algorithm [37] usesa region growing strategy along with a set of representative planes for polygonal mesh simpliﬁcation. Chazelle et al. [38] present a method for convex decomposition that also uses a region growing with randomly selected starting faces. The watershed algorithm, which is effective for image segmentation, is in fact a region growing approach with multiple seed points. Accordingly, using the watershed algorithm for the segmentation of 3D surface mesh has also been studied [5], [39], [40]. However, region growing is a greedy algorithm, and these methods locally focus on the faces of the surface mesh. Consequently, they all suffer from the over-segmentation problem and always output fragmented surface patches. In this paper, although the simple region growing strategy is used, it is performed on the MAT domain with novel energy terms and strategies, which results in superior segmentation results that are more in line with human cognition.3 PRELIMINARY3.1 Medial axis transform (MAT)The medial axis transform (MAT) [14] of a 3D shape S is deﬁned by two parts: (1) the centers of a set of maximal spheres inscribed to the shape S, called medial axis; and (2) the radius function associated with each such sphere center. See Fig. 3 for an illustration. In general, the MAT of a 3D shape S consists of 2D non-manifold surface sheets and 1D curve segments, with the radius function deﬁned on this complex. The MAT is a complete shape descriptor, which means that it can be used to reconstruct the original domain. By its deﬁnition, the MAT explicitly encodes both structural and geometrical natures in the interior of a 3D shape, which is highly informative for shape analysis.3.2 MAT graphMedial mesh. The key to SEG-MAT is an MAT represented as a triangle mesh, called a medial mesh (see Fig. 4 (a)). A vertex mi = (ci, ri) of the mesh denotes the maximally inscribed sphere centered at the point ci with radius ri. Let eij = {mi; mj} denote the edge of the mesh connecting two vertices mi and mj. Then the edge eij deﬁnes a medial cone, which is the convex hull of the two spheres mi and mj (see Fig. 5 (a)). Let fijk = {mi; mj; mk} denote the triangle face with the vertices mi, mj, and mk. Similarly, the face fijk deﬁnes a medial slab, which is the convex hull of the three spheres mi, mj, and mk (see Fig. 5 (b)). The input 3D shape is then approximated by the union of all these medial cones and medial slabs.1 234 5 61 2 3 4 5 6(a) (b)Fig. 4. Visualization of the medial mesh and the deﬁnition of the MAT graph. (a) The medial mesh of a hand model. (b) The MAT graph representation with the face nodes and the edge nodes.4(a) (b)Fig. 5. The medial primitives. We show a cone (a) and a slab (b) given by the interpolation of their medial spheres.MAT graph. Medial cones and medial slabs serve as the elementary primitives in our segmentation operations. Therefore, we need to encode the connectivity between these primitives by deﬁning the MAT graph on the medial mesh, as shown in Fig. 4 (b). There are two types of nodes in the MAT graph: (1) a face node N f given by a triangle face f = {mi; mj; mk}; (2) an edge node N e given by an edge e = {mi; mj}. We use R(Ni) to denote the average medial sphere radius of a face node or an edge node Ni. Two nodes of the MAT graph are connected if they share at least one vertex on the medial mesh. MAT computation. The MAT of a 3D object is known to be sensitive to boundary noise. Over the years some effective methods [41], [42] have been proposed for producing a compact and accurate MAT of a 3D object. In this paper, we use the Q-MAT [41] method to generate the input MAT to our method.3.3 Segmentation criteriaWe use the term junction to refer to a common boundary along which adjacent parts or segments meet. The mathematical model that characterizes these junctions is based on a number of segmentation criteria. Instead of proposing (a combination of) low-level feature descriptors, we capture higher-level shape context by expressing the segmentation criteria in terms of MAT properties. Inspired by wellestablished Gestalt principles [43], we deﬁne a hierarchical taxonomy of junction types based on the topological and geometrical properties of the MAT.RR(a) (b)Fig. 6. Illustration of the topology junctions: (a) non-manifoldness and (b) change of dimensionality.(A) MAT topology. This type of junction characterizes the structural (topological) clues for identifying the components of a 3D shape. See Fig. 6 for an illustration and Sec. 4.1 for the detailed deﬁnitions of the junctions.• (AA) Non-manifoldness (Fig. 6(a)): Structural branchings (e.g., two legs connected to one torso) indicate a component-wise assembly of the object. Here, the MAT has, e.g., three edges meeting ina common vertex or three sheets meeting along a common edge.• (AB) Change of dimensionality (Fig. 6(b)): Transitions from plate-like regions to tube-like regions also indicate part boundaries. Here, the MAT has a 2D sheet connected to a 1D edge.RRR(a) (b)Fig. 7. Illustration of the geometry junctions: (a) thickness variation and (b) sharp bending.(B) MAT geometry. This type of junction characterizes the geometrical clues for detecting the part boundaries of a 3D shape on the MAT. See Fig. 7 for an illustration.• (BA) Thickness variation (Fig. 7(a)): Part boundaries are also perceived in the vicinity of concave features (valleys, incisions). On the MAT this coincides with signiﬁcant variations of the sphere radii (thickness variation).• (BB) Sharp bending (Fig. 7(b)): Part boundaries in articulated objects are detected by observing changes of the medial axis orientation, leading to small angles between adjacent MAT edges or sheets.According to these insights on how two or more parts are joined together via junctions, we will give the detailed algorithm of SEG-MAT for detecting these junctions on the MAT in the next section.4 METHODWe will ﬁrst provide an overview of our method and then elaborate on the details of its main steps in the subsequent sections. As shown in Fig. 8, our method has the following four main steps for segmenting a given 3D shape. (1) Initialization (Sec. 3.2): we compute the MAT (called the base MAT) of the input 3D object and deﬁne its MAT graph. (2) Structural decomposition (Sec. 4.1): we further simplify the base MAT to obtain a structured MAT to derive the topological junctions (i.e., non-manifoldness and change of dimensionality); and cut the MAT graph into connected components along the junctions explicitly suggested by the structured MAT. This step yields a coarse segmentation result. (3) Geometrical decomposition (Sec. 4.1 and Sec. 4.2): we perform region growing on each connected component by analyzing the geometrical junctions (i.e., thickness variation and sharp bending) to obtain a reﬁned segmentation of the MAT from the coarse segmentation. (4) Finally, we map the segmentation results from the MAT domain to the surface mesh of the input shape, and further reﬁne the segmentation results and cut boundaries (Sec. 4.4).4.1 Structural decompositionThe aim of structural decomposition is to detect topological junctions (i.e., non-manifoldness and change of dimensionality) to segment the MAT into a collection of curves and5MAT Graph  DefinitionMATComputationStructuralDecompositionMATSimplificationGeometricalDecompositionRegion GrowingMap from MATto SurfaceGraph-CutSection 3.2 Section 4.1 Section 4.2 & 4.3 Section 4.4Fig. 8. An overview of the key steps of SEG-MAT. The upper row: the title of each main step; the lower row: the key technique used in each main step.sheets, thus producing an initial coarse segmentation of the input shape. Ideally, we would like to represent a tubelike part by a skeletal curve and a plate-like part by a surface sheet, and therefore the joints between these parts can be easily identiﬁed. Nonetheless, the accurate MAT of a tube-like part may appear as a thin surface strip and the MAT of a plate-like part may contain insigniﬁcant branches due to small disturbance on the surface. We resolve this issue by using the simpliﬁcation mechanism of the Q-MAT [41] method to further simplify the base MAT to obtain a highly simpliﬁed MAT, which is named structured MAT in this paper. A comparison between the base MAT and the structured MAT is shown in Fig. 9.(a) (b)Fig. 9. Comparison between the base MAT and the structured MAT. (a) The medial mesh of a base MAT where the tube-like parts appear as narrow surface strips; (b) the medial mesh of the corresponding structured MAT with clean curve-sheet structures.In the simpliﬁcation, the triangular faces are iteratively collapsed into edges. With the error control and topology preservation mechanism of Q-MAT [41], the MAT of tubelike parts will be simpliﬁed into curve skeletons, while the plate-like parts will be preserved as sheets but the insignificant branches will be removed. Please refer to the original paper [41] to see more detailed properties of the robustness of the simpliﬁcation. In essence, the simpliﬁcation produces a clean and simple curve-sheet representation, extracting an explicit structure of the base MAT. Then we identify the junctions on the structured MAT by detecting the following joints:• Seam edge: an edge of the structured MAT shared by at least three triangles (Fig. 10 (a)).• Seam vertex: a vertex of the structured MAT shared by at least three edges (Fig. 10 (b)).• Edge-triangle vertex: a vertex of the structured MAT jointly shared by an edge and a triangle (Fig. 10 (c)).• Triangle-triangle vertex: a vertex of the structured MAT shared by at least two triangle faces, while the faces do not share any edge (Fig. 10 (d)).(a) (b) (c) (d)Fig. 10. Four types of joints on the structured MAT used for structural decomposition: (a) seam edge; (b) seam vertex; (c) edge-triangle vertex; (d) triangle-triangle vertex.Accordingly, we decompose the structured MAT into curves and sheets using the above-mentioned joints. Then we cut the MAT graph into a set of connected components by mapping each node to the decomposed part with the closest Euclidean distance.4.2 Geometrical decompositionGiven a coarse segmentation C = {C1, C2, ..., Cn} by the structural decomposition, in this step, we use a region growing strategy to further segment each part Ci by incorporating the geometrical clues, i.e., detecting thickness variation and sharp bending junctions. The algorithm is detailed in Algorithm 1 with pseudo-code and the growing process is visualized in Fig. 11.(a) (b) (c) (d) (e)Fig. 11. The region growing process on the MAT of a shape. (a) The ﬁrst seed node with the largest radius on the MAT is selected ; (b) the ﬁrst part has grown; (c) a new seed node is selected; (d) the second part has grown; (e) all the parts have grown. To clearly focus on the growing process, the MAT is givens as a single part which is not processed by the structural segmentation.Region growing. The seeded region growing [44] is a simple unsupervised method ﬁrst proposed for image segmentation. It examines neighboring nodes of initial seed points and determines whether the neighbors should be added to the region. The process is iterated until there are no valid nodes that can be added. Two major problems need to be addressed when region growing is used for segmentation: how to select the seed nodes and what criteria should be adopted to characterize the growing cost. Two values need to be determined when region growing is used: the growing threshold and the minimal region threshold. Seed points selection. Determining all the seed points at the beginning is a hard problem and sometimes it needs complex computations to ﬁnd the salient points or the input from users. Instead, in each iteration, we directly choose the unvisited node that has the largest medial sphere radius among all the unvisited nodes as the seed point. This simple heuristic takes advantage of the saliency of the largest radius, making the algorithm directly handle the next-thickest-part after each iteration, which is more efﬁcient and demonstrated to be effective. Growing cost. We propose a growing cost function on the MAT graph from two aspects. The ﬁrst is the medial axis,6since the radius variations and the bending angles between the triangles are important indicators of geometrical variation of a shape on the medial mesh. The second is the medial primitives (i.e., medial cones and medial slabs); they characterize the change of geometry on the level of the shape surface. Consequently, we formulate the growing cost using two terms: the medial axis term Cma and the medial primitive term Cmp. For any two adjacent nodes Ni and Nj of the MAT graph, the medial axis term Cma(Ni, Nj) is deﬁned asCma(Ni, Nj) = |R(Ni) − R(Nj)|min(R(Ni), R(Nj)) + απ − θNi,Njπ , (1)where R(Ni) and R(Nj) are the average radii of Ni and Nj; θNi,Nj(θNi,Nj < π) is the dihedral angle if Ni and Nj are both face nodes, or the angle between two edges if Ni and Nj are both edge nodes, else 0 if Ni and Nj are of different types. The two terms of Cma(Ni, Nj) in Eq. 1 account for the thickness variation and bending angle between two nodes respectively. They are combined with a weight α = 0.05, which is an empirical value based on extensive tests. To deﬁne the primitive term Cmp, we ﬁrst recall the medial primitives in an MAT (see Sec. 3.2), namely, the medial cone deﬁned by an edge and the medial slab deﬁned by a triangle face of the medial mesh. As shown in Fig. 12, the union of two adjacent primitives will form two angles on the two sides. These angles are concentrated expressions of the thickness change and sharp bending on the surface; that is, either thickness change or sharp bending will lead to these angles between primitives. The medial primitive term Cmp is deﬁned asCmp(Ni, Nj) = ̸ (N + i , N + j ) + ̸ (N − i , N − j )2π , (2)where ̸ (N + i , N + j ) and ̸ (N − i , N − j ) denote the primitive angles computed by two pairs of normals (n1, n2) and (n3, n4) (see Fig. 12) of the two sides respectively. Finally, the mesh term Cma and the primitive term Cmp are combined as follows to derive the ﬁnal growing cost function:C(Ni, Nj) = min{Cma(Ni, Nj), λCmp(Ni, Nj)}. (3)Here λ is the weight factor ﬁxed at 1.5 empirically. Since both Cma and Cmp are the expressions of geometrical change from two perspectives, using the min operator results in higher reliability; that is, only if the values of the two (weighed) terms both exceed a threshold, a segmentation is suggested.(a) (b)n1 n2n3 n4Fig. 12. Two-side primitive angles. (a) Two joining slabs; (b) illustration of two angles (given by two pairs of normals (n1, n2) and (n3, n4) ) formed on the two sides.Growing threshold. The growing threshold δ is an important parameter to gauge the growing process. The node Nj will be added into the region of Nj only if C(Ni, Nj) ≤ δ. It is worth noting that, people’s sensitivity to geometrical variation for different forms of parts differs. A key observation is, for some “thin” parts, although the geometry changes drastically on this part, people still usually deem it as a single part. For example, the upper piece of the shoe model in the inset, despite being highly non-convex, should be deemed as a whole part. Based on this insight, given a set of curves and sheets produced by structural decomposition, we ﬁrst measure how “thin” a component Ci is byρ(Ci) = S(Ci)Rmax(Ci), (4)where S(Ci) is the length of Ci if it is a curve segment of structured MAT or the square root of the area of Ci if it is a sheet, and Rmax(Ci) is the largest radius on Ci. Intuitively, it measures how “thin” a component is in terms of the ratio of the shape expansion S(Ci) to the shape thickness expressed by radius Rmax(Ci). If Ci is a thin tube or plate, ρ(Ci) should be fairly large. For the thin parts, we propose to use a larger threshold to encourage merging so as to maintain the integrity of these tubes or sheets by giving them higher tolerance to geometrical change. Therefore, the growing threshold is automatically adjusted byδ = δ0 · σ(log(ρ(Ci)). (5)Here ρ(Ci) is the thinness of Ci, and σ(x) is an indicator function where σ(x) = x if x ≥ 3 or it is 1. This indicator function is to ﬁlter out the bulky parts that are not thin enough and thus not considered for threshold adjustment. δ0 is the original threshold given by a user; note that δ ≥ δ0. Our tests have shown that this automatic threshold adjustment scheme works effectively for the segmentation of general shapes. The default value of δ0 is set to 0.015 in this paper, but can be tuned according to users’ requirements in practice, see Sec. 5.6. Minimal region threshold. As a necessary parameter of the region growing algorithm, minimal region threshold η is to guarantee that no region is smaller than this threshold to avoid fragmented segmentation. Here we consider a generated part as negligible if the ratio of the number of its nodes to the number of all the nodes of the entire graph is less than η. The negligible parts will be merged into one of its adjacent parts. We set η to 0.2% and evaluate it in Sec. 5.6.4.3 SwallowingAs aforementioned, the MAT is sensitive to the boundary noise; small perturbations to the shape boundary will result in numerous long and unstable spikes on the MAT. For the segmentation task, these spikes should not be treated as valid parts. We therefore propose an efﬁcient method, called swallowing, to handle these spikes in the process of region growing.7Algorithm 1: Region Growing on the MAT.Input: MAT Graph G = {{Ni}, E}, which is cut into a set of components C = {C1, C2, ..., Cn} // The growing cost δ0 and the least node ratio η are pre-deﬁned. Output: Fine-grained MAT components R = {R1, R2, ..., Rm} Build an empty Queue Q; repeatInitialize a new part R′; seed = the unvisited node N with the largest R(N); Q.push(seed); Mark seed as visited; while Q is not empty doNi ← Q.pop(); Add Ni to part R′; for each Nj where (Ni,Nj) ∈ E doif Nj is unvisitied and C(Ni, Nj) < δ0 · σ(log(ρ(Ci)) thenQ.push(Nj); Mark Nj as visited;if the node number ratio of R′ >= η thenfor each unvisited node Nk doif Nk should be swallowed by R′ thenAdd Nk to the part R′; Mark Nk as visited;Add R′ to R; elseMark the nodes in R′ as negligible nodes;until all nodes are visited;Since the growing starts from the node with the largest radius among the unvisited nodes, a newly generated volumetric region can be viewed as the trunk of this part. As shown in Fig. 13, a generated region can include most of the unstable spikes inside this trunk part. Therefore, once a volumetric region is generated, we ﬁnd out the unvisited nodes as well as the negligible nodes whose corresponding faces or edges in the MAT are enclosed in or intersect with any spheres in the generated region. Then we merge these nodes into the generated region and mark them as visited on the graph. This strategy makes the growing process only focus on the backbone of the MAT and swallow the branching spikes, making our algorithm insensitive to shape noise (see the validation in Sec. 5.5) and robust to the instability of the MAT.4.4 Transferring segments to surfaceBefore transferring the segmentation results from the MAT to the surface, we adopt a post-processing step to further reﬁne the results. Following Kaick et al. [12], we compute a histogram of the radius distribution of each part, and measure the Earth Mover’s Distance (EMD) [45] between two radius distributions; two adjacent parts will be merged iteratively if they have matched radius distribution. This step employs more global information beyond the local region growing to further avoid over-segmentation.s1 s2 s3RR(a) (b) (c) (d)Fig. 13. The swallowing process. (a) The MAT of a shape with spikes (s1, s2 and s3 colored in gray) due to boundary noise; (b) start growing from a seed node (red); (c) the grown part (colored in blue) with its corresponding growing trace (colored in red), and the region includes s1, s2 and s3; (d) the spikes are swallowed by the grown region.In order to obtain smooth cut boundaries, we do not directly map the segmentation results from the MAT graph to the surface mesh. Consider the dual graph of the surface mesh G = {F, N}, where F denotes the set of nodes representing the triangle faces and N the set of edges between neighboring faces. We formulate a k-way graphcut optimization problem to ﬁnd the optimal MAT segment for each triangle face by minimizing the following energy:E(L) = Xf∈F Ed(lf) + ω X(f,g)∈N Es(lf, lg), (6)where Ed is the data term to penalize the assignment of a face node f to the label lf, which is measured by the closest distance between f and a corresponding MAT segment. Speciﬁcally, it is computed as the Euclidean distance between the centroid of a face and its closest medial sphere of an MAT segment, and then normalized by the length of the diagonal of the object’s bounding box. The second term Es(lf, lg) is the smoothness term deﬁned asEs(lf, lg) =( 0 lf = lg min( φ(f,g)π , 1) lf ̸= lg, (7)where φ(f, g) is the exterior dihedral angle between face f and face g. The parameter ω = 0.3 balances the data ﬁtting term and the smoothness term. We use the method of [46] to efﬁciently solve this combinatorial optimization problem. This step optimizes the correspondences between the MAT segments and the surface triangles, encouraging the cut boundaries to smoothly pass through the concave valleys of the surface mesh.5 EXPERIMENTAL RESULTSIn this section, we conduct extensive comparisons and discussions to evaluate our algorithm. We use the Princeton Segmentation Benchmark (PSB) [24] to compare with rulebased methods, and use a subset of the testing data of ShapePFCN [2], which is collected from ShapeNet [47], to compare with learning-based methods. The ShapeNet models are remeshed into watertight manifold surfaces [48] ﬁrst for robust MAT computation. Following the error control metric of Q-MAT [41], the base MAT is computed by setting the average slab quadratic error (SQE) to 0.5% and for the structured MAT it is set to 3%, both relative to the length of the diagonal of the8bounding box. All the experiments are performed on a machine with Intel Core i7-7700K 4.2GHz CPU and 32GB RAM.SEG-MAT WCSeg RandCuts SDFFig. 14. Qualitative comparison with representative rule-based geometrical segmentation methods.We show our segmentation results for a variety of 3D shapes in Fig. 15. We use the same parameter settings for shapes of different categories and different datasets. Our method is able to segment various types of shapes and determine the number of parts automatically using consistent settings, which demonstrates the ﬂexibility and robustness of our method.TABLE 1 Comparison with rule-based geometrical method on PSB dataset for each object category. Entries represent the rank of the method based on the Rand Index evaluation metric (1 is the best, and 7 is the worst).SEG WC Rand Shape Norm Core RandMAT Seg Cuts Diam Cuts Extra WalksHuman 2 1 3 4 5 6 7 Cup 1 2 3 7 4 5 6 Glasses 1 4 2 5 3 6 7 Airplane 1 2 4 3 5 6 7 Ant 1 2 4 3 5 6 7 Chair 1 3 7 4 2 6 5 Octopus 2 1 6 3 5 4 7 Table 1 2 7 5 3 6 4 Teddy 2 3 1 4 6 5 7 Hand 2 3 1 6 5 4 7 Plier 1 2 4 7 5 3 6 Fish 2 1 5 3 6 4 7 Bird 1 2 3 4 6 5 7 Armadillo 3 2 1 4 6 7 5 Bust 3 2 1 4 6 5 7 Mech 3 2 6 4 1 7 5 Bearing 1 3 4 2 5 7 6 Vase 3 2 1 5 6 4 7 FourLeg 1 2 4 3 5 6 7Overall 1 2 3 4 5 6 75.1 Comparison with rule-based methodsWe ﬁrst qualitatively and quantitatively evaluate our method with comparisons to rule-based segmentation methods that use geometrical analysis for single shape segmentation on the PSB [24]. These methods include weakly convexTABLE 2 Analysis of the trade-off among computation time, segmentation quality and usability. (*: whether the numbers are obtained by tuning the parameters for each shape or category separately; #: the computation time is measured when the MAT is given, while the MAT computation time for one shape using Q-MAT [41] is about 4s.)SEG-MAT Shu et al. WCSeg RandcutAvg. Computation Time 4.7s# 216.3s 127.4s 78.8s Rand Index 0.114 0.118 0.123 0.157 Per-category Tuning∗ No Yes No Yessegmentation (WCSeg) [12], randomized cuts (RandCuts) [13], shape diameter function (SDF) [10], normalized cuts (NormCuts) [13], core extraction (CoreExtra) [22], random walks (RandWalks) [21], primitive ﬁtting (FitPrim) [49], and K-Means [23]. Fig. 14 shows the qualitative comparison results with some representative methods. It can be observed SEG-MAT gives better segmentation results that are more consistent with human’s perception. As shown in Table 3, we use four metrics deﬁned by the PSB [24], i.e., Rand Index, Cut Discrepancy, Hamming Distance and Consistency Error, for quantitative comparison. It can be seen that our algorithm is comparable or better than the state-of-the-art methods, but is about one order of magnitude faster (see the next paragraph). Following the metrics in [24] and [12], we show in Table 1 the rankings of these algorithms for each shape category in terms of the Rand Index score. SEG-MAT performs the best in 10 categories out of 19 categories, while none of the other methods win in more than 5 categories. We also jointly examine the average running time, performance and usability for different methods on the PSB dataset, of which results are shown in Table 2. The usability is embodied by whether the results are obtained by using category-speciﬁc or shape-speciﬁc parameters. Here we also include an unsupervised learning-based method [11] that aggregates multiple shape signatures for comparison. We can see the other methods that need to extract low-level geometrical descriptors usually take a longer time to process a single 3D shape. However, SEG-MAT uses signiﬁcantly less computation time and consistent parameters for different shapes and categories but achieves the best performance.5.2 Comparison with learning-based methodsComparison with unsupervised learning methods. The unsupervised learning methods do not require manually annotated labels. The segmentation also relies on the intrinsic geometrical properties of a shape rather than predeﬁned labels and the results follow the minima rule [1]. Therefore, learning-based methods of this category have the same goal as our algorithm and can be included for comparison. Recently, Tulsiani et al. [25] and Sun et al. [26] propose unsupervised methods for structural analysis of 3D shapes. They learn to parse a 3D shape into a set of cuboid primitives and induce a segmentation by the projection of the predicted primitives onto the original shape. We follow their metrics for evaluation: we use a tight cuboid primitive (i.e., minimal oriented bounding box, see Sec. 5.7 for the detail) to represent each part; then a shape is rebuilt by a set of primitives and we evaluate the reconstruction error.9Fig. 15. Segmentation results of SEG-MAT for various shapes. We always use consistent parameter settings for different shapes and datasets; the number of parts of each shape is determined by the algorithm automatically.TABLE 3 Comparison with rule-based segmentation algorithms using four metrics deﬁned on the PSB dataset: Rand Index, Cut Discrepancy, Hamming Distance and Consistency Error. RI: Rand Index; CD: Cut Discrepancy; GCE: Global Consistency Error; LCE: Local Consistency Error; HD: Hamming Distance; HD-Rm: Hamming missing rate; HD-Rf: Hamming false alarm rate. The metrics are scaled by 1000 for better readability.RI CD GCE LCE HD HD-Rm HD-RfSEG-MAT 114.6 212.1 95.9 63.3 117.1 115.1 119.1 WCSeg 122.7 214.6 98.1 62.4 118.4 120.6 116.3 RandCuts 157.4 274.1 122.1 71.1 136.2 142.9 129.5 ShapeDiam 175.7 274.7 129.6 82.3 166.5 186.7 146.2 NormCuts 178.0 299.4 150.4 97.0 175.6 183.1 168.1 CoreExtra 210.8 375.2 135.0 86.3 169.4 126.2 212.5 RandWalks 229.7 384.5 175.1 103.3 208.2 205.6 210.9 FitPrim 216.4 349.4 217.2 143.0 241.1 285.0 197.1 KMeans 254.9 420.0 249.3 166.8 277.1 334.2 220.1TABLE 4 Quantitative comparison with the unsupervised learning-based methods using ShapeNet [47] data. We report the IoU and the Chamfer Distance between the generated primitive-based representations and the original shapes.IoU Chamfer DistanceAirplane Chair Table Airplane Chair TableTulsiani et al. 0.271 0.313 0.344 0.0531 0.0506 0.0537 Sun et al. 0.445 0.471 0.409 0.0301 0.0338 0.0434 SEG-MAT 0.486 0.474 0.436 0.0260 0.0395 0.0347Fig. 16 shows qualitative comparison results with these methods, where our results are more structurally meaningful and able to capture more detailed components. Table 4 reports the intersection-over-union (IoU) and the ChamferDistance between the primitive-based representations and the target shapes. We obtain smaller reconstruction errors in most categories, which means our method can achieve better approximation accuracy as well as segmentation quality. Note that their methods need to be trained separately on each category using a large amount of data, while we use consistent parameter settings for all categories.Discussion of supervised learning (semantic) methods. The supervised learning methods for semantic segmentation have different applications, goals and evaluation metrics compared to the methods based on geometrical analysis. At the beginning of this paper, we give a comparison between the segmentation results of semantic and geometrical methods in Fig. 1, which shows semantic segmentation targets integral semantic clusters but does not focus on10Input Tulsiani et al. Sun et al. SEG-MAT Input Tulsiani et al. Sun et al. SEG-MATFig. 16. Qualitative comparison with unsupervised learning methods for primitive-based approximation and part-based segmentation.TABLE 5 Elaboration on the key differences between semantic segmentation and geometrical segmentation methods.Semantic learning Geometrical analysisApplication conditionA group of similar shapes in the same categoryArbitrary single shapeProduce language labelYes NoNeed human annotationYes NoSegmentation criteriaConsistency with pre-deﬁned semantic labelsMinima rule (parts are weakly convex)Number of segmentsSame within a categoryDifferent within a categoryGround truth Only one One or moreEvaluation metricsLabeling accuracy Convexity, partbased abstraction error, Rand Index, etc.Representative methodsShapePFCN [2], Xu et al. [18]Rule-based: WCSeg [12], RandCut [13] Learning-based: Su et al. [25], Sun et al. [26]part instances. In Table 5, we further elaborate on their differences from various aspects to give more insights. Speciﬁcally, we discuss the ShapePFCN [2], a state-ofthe-art supervised learning method. The ShapePFCN aims to label a 3D shape with pre-deﬁned semantic meanings and needs annotated data for training. With strong supervision, ShapePFCN achieves superior segmentation results with interpretable language labels. However, some issues of thesemantic segmentation methods cannot be neglected. These methods rely on the ﬁxed semantics of the training data and focus on minimizing the labeling error, but barely consider the explicit geometrical properties of a 3D shape. This can lead to high labeling accuracy, but sometimes the results are counter-intuitive. As shown in Fig. 17 (a), for the hand model, ShapePFCN produces some fragmented pieces on the surface where the geometry does not change appreciably. Another interesting phenomenon is, even the vase shown in Fig. 17 (b) does not have a handle, ShapePFCN still labels a handle part to match the semantics of the training data. Our method works well for segmenting these two simple models, with the help of the clear geometrical differentiation.ShapePFCN SEG-MAT (a) ShapePFCN SEG-MAT (b)Fig. 17. Visual comparison between ShapePFCN (supervised learning method for semantic segmentation) and SEG-MAT.5.3 Comparison with skeleton-based methodsIn this section, we evaluate our method with comparisons to two representative segmentation methods based on skeletal representations, i.e., generalized cylinder decomposition (GCD) [50] and skeleton cut space analysis (Skel-Cut) [33].11The GCD method, in essence, is still built on the geometrical simplicity given by the 1D-curve representation, but it is deﬁned as generalized cylindricity. Therefore, the method shows its defects when applied to complex geometries and non-cylindrical shapes. As the two shapes shown in Fig. 18 (a), the curve skeletons produced by the generalized cylinders cannot faithfully represent the topology of the original shapes.(a) (b)Fig. 18. Analysis of the related skeleton-based methods, i.e., GCD and Skel-Cut. (a) Curve skeleton representations for two models given by the generalized cylinders. (b) The visualization of the metrics used in SkelCut: medial geodesic function (MGF) (left) and the cut-length histogram (right).A more closely relevant method is Skel-Cut, given that the skeletal representations they use also contain medial surfaces. However, the metric to analyze the cut space is solely based on the medial geodesic function (MGF) [34], of which computation is correlated with the MAT but essentially a distance metric on the surface mesh. Since the Skel-Cut method does not exploit the intrinsic properties of the MAT such as the radius, branches and topology, it is more tailored to the shapes that have distinguishable distributions of the MGF-based cut-length, such as organic shapes. Fig.18 (b) visualizes the MGF of a shape and the corresponding cutlength histogram; it is very difﬁcult to ﬁnd peaks and valleys on the histogram to differentiate multiple parts based on the algorithm of Skel-Cut.GCD Skel-Cut SEG-MATFig. 19. Qualitative comparison with representative skeleton-based methods, i.e., Generalized cylinder decomposition [50] (GCD) and SkelCut [33].We compare our method with these two methods using the PSB dataset and a set of shapes from the ShapeNet. The qualitative results are shown in Fig. 19 and the quantitativeTABLE 6 Quantitative comparison with the skeleton-based methods on the PSB. The CE is reported as the mean of GCE and LCE; the HD is report as the mean of HD, HD-Rm and HD-Rf. The metrics are scaled by 1000 for better readability.RI CD CE HDGCD 159.4 252.2 64.7 125.3 Skel-Cut 200.3 288.5 124.6 173.9 SEG-MAT 114.6 212.1 79.6 117.1results in Table. 6. The comparisons demonstrate the generality and robustness of our method to complex geometries especially when a shape is composed of many components with varying properties. For the time efﬁciency, our method is signiﬁcantly faster than the others; the average computation time for our method is less than 10 seconds, while the GCD is 134 seconds and Skel-Cut 97 seconds. Also, note we use consistent parameter settings (the parameters of GCD need to be tuned on different categories).5.4 Ablation studiesWe verify the necessity of the key modules in our pipeline by conducting ablation studies. We alternatively remove each module, i.e., swallowing, merging and graph-cut, and evaluate the performance. Fig. 20 shows qualitative segmentation results using different conﬁgurations, from which we can observe that: (1) the swallowing process effectively helps remove fragmented patches caused by the unstable “spikes”; (2) the merging process combines the similar parts caused by local variation, giving simpler and more integral segmentation; (3) the graph-cut leads to smoother cut boundaries. We also report the quantitative evaluation results on the whole dataset in Table. 7.w/o swallowingw/ swallowingw/o mergingw/ mergingw/o graph-cutw/ graph-cutFig. 20. Ablation study on some modules of our algorithm: swallowing, merging and graph-cut.TABLE 7 Quantitative ablation study on the different modules in the SEG-MAT pipeline. We report the Rand Index scores on the PSB dataset for different conﬁgurations.w/o w/o w/o fullswallowing merging graph-cut conﬁgurationRandIndex 0.135 0.129 0.127 0.11412σ = 0.0% σ = 0.2% σ = 0.5% σ = 1.0%Fig. 21. Robustness of SEG-MAT against surface noise. The ﬁrst row shows the medial meshes and the second row shows the corresponding segmentation results. We add to each mesh vertex a white Gaussian noise with the mean value equal to zero and the standard deviation σ = 0.0%, 0.2%, 0.5%, 1.0% of the length of the diagonal of bounding box respectively. Using a same set of parameter values, SEG-MAT is able to produce almost consistent segmentation results.5.5 Robustness against noiseAlthough the MAT itself is very sensitive to boundary noise, our algorithm is resilient in the presence of signiﬁcant noise. Fig. 21 shows an example of applying our algorithm to a model with increasing noise, with all the parameters being ﬁxed. It can be observed that SEG-MAT produces almost consistent segmentation results at different noise levels. The robustness of SEG-MAT to surface noise is due to the use of the region growing technique and the swallowing process. Region growing is a greedy strategy, and hence we can generate stable regions by greedily ﬁnding similar neighbors rather than globally considering the insigniﬁcant branches. More importantly, the “swallowing” (Sec. 4.3) process merges the noisy branches into the stable regions, and thus the noisy branches will not be considered as valid parts. Therefore, the algorithm only focuses on the backbone of the MAT and is insensitive to noise. More results are shown in Fig. 22 for some shapes with signiﬁcant noise.Fig. 22. More segmentation results of shapes with signiﬁcant noise, while SEG-MAT is still able to segment these shapes into meaningful parts.5.6 Parameter analysisSince our method is geometry-driven, like all the existing methods, there is a set of parameters in the algorithm to adapt to the geometrical information from different perspectives. We use consistent parameter settings for producing all the results for comparison, which demonstrates that our default values work well for general models, such as these shapes in the PSB [24] and ShapeNet [47]. It is however possible for users to tune some parameters to adjust the desired segmentation. We only leave twoδ = 0.01 δ = 0.015 δ = 0.03Fig. 23. Segmentation results for a bird model with an increasing growing threshold δ. A smaller δ produces more ﬁne-grained segmentation that captures more detail.η = 0.2% η = 0.3% η = 0.4%Fig. 24. Segmentation results for a ﬁsh model with increasing values of the minimal region threshold η. A larger η results in removing tiny parts in the segmentation result.TABLE 8 Evaluation on the sensitivity of the other parameters. We report the maximal and minimal Rand Index score achieved within the range of parameter test.Parameter Function Default value RI-min RI-maxα weight of Eq. 1 0.05 0.114 0.118 λ weight of Eq. 3 1.5 0.113 0.121 ω weight of Eq. 6 0.3 0.114 0.119necessary parameters of region growing algorithm, i.e., the growing threshold δ and the minimal region threshold η (see Sec. 4.2), to users to generate different levels of details; other parameters are recommended to be ﬁxed to the default values obtained by our extensive experiments. We discuss the effect of different values of these two parameters on the segmentation results for a better understanding of the mechanism of SEG-MAT. The growing cost tolerance δ affects the sensitivity of the segmentation to the geometrical variation. As shown in Fig. 23, a smaller δ captures more detailed geometrical change and results in a ﬁner-grained segmentation. We use δ = 0.015 for the evaluations in this paper. The minimal region threshold η is used to control the minimum size of a part, while using a small η leads to preserving the tiny parts of a 3D shape. See Fig. 24 for the validation experiments using different values of η. The default value is η = 0.2% for the evaluations in this paper. For the other parameters, following [12], we change their values in a range within 30% (±15% added to each value with 5% changed each step). Accordingly, we report the range of the variation of the Rand Index on the PSB dataset, which is shown in Table. 8. It can be seen that the segmentation quality is largely similar.5.7 More applicationsWe extend our method to make it applicable to more tasks. In this section, we demonstrate two applications, i.e., primitive-based abstraction and point cloud segmentation. Primitive-based abstraction. There has been growing interest in parsing a 3D shape into a primitive-based representation [25], [26], [51], of which goal is to assemble a13target shape using a set of volumetric primitives. A good primitive-based approximation is geometrically expressive and compact, which means it can abstract complex 3D shape structures using the fewest possible primitives. To this end, given a 3D shape, we ﬁrst run our algorithm to segment it into a set of structurally meaningful parts, and then ﬁnd a minimal oriented bounding box (MOBB) [52] for each part. The results are shown in Fig. 16. Point cloud segmentation. SEG-MAT can also be used for the segmentation of point clouds. We ﬁrst use Deep Point Consolidation [53] to compute a meso-skeleton from a noisy or incomplete input, and then use the closest distance between each medial point to the input point cloud as the approximation of the radius. Then the MAT graph is constructed and the normals are estimated using the knearest neighbors of each medial point. Since there are no surfaces on the meso-skeleton, we simply remove the medial primitive term Cmp in Eq. 3. Some results are shown in Fig. 25.Fig. 25. Segmentation results of SEG-MAT for point clouds.6 CONCLUSIONWe present a simple, robust and efﬁcient method, called SEG-MAT, for 3D shape segmentation using the medial axis transform (MAT). The use of the structural and geometrical information encoded in the MAT makes SEG-MAT effective for segmenting arbitrary shapes across a wide range of complexities and noise levels. Given a 3D shape with its MAT, we ﬁrst perform structural decomposition by detecting the joints using the simpliﬁed MAT, and then perform geometrical decomposition by region growing. Finally, the segmentation results are transferred from the MAT to the shape surface. The extensive evaluations and comparisons with the existing segmentation methods demonstrate that SEG-MAT is a superior and competitive geometry-driven method for real-world applications of 3D shape analysis. Limitations and future work. SEG-MAT would fail to segment the parts that have ﬂat geometries and constant thickness. Fig. 26 shows two examples, each of which contains a part that is not segmented by SEG-MAT. Here, the MAT surface of such a part is a single ﬂat sheet and the radius function is constant. SEG-MAT fails to segment it because there is neither a large bending angle, nor a radius(a) (b)Fig. 26. Some failure cases of SEG-MAT. (a) Two pieces of the glasses should be segmented into two distinct parts; (b) the tail and the ﬁn of the ﬁsh should be decomposed.variation, nor a structural change on the MAT to trigger a segmentation. A potential solution to this problem could be based on the analysis of the medial curve of the MAT surface sheet to detect the narrow passage connecting these ﬂat parts, following the idea of the erosion function of the MAT [54].ACKNOWLEDGMENTSWe would like to thank the anonymous reviewers for their valuable feedback and Yiling Pan for her help with data processing. This work is supported by the Gottfried Wilhelm Leibniz program by DFG and the grants from National Natural Science Foundation of China (NSFC) (No. 61772301 and No. 61772016).REFERENCES[1] D. D. Hoffman and W. A. Richards, “Parts of recognition,” Cognition, vol. 18, no. 1-3, pp. 65–96, 1984.[2] E. Kalogerakis, M. Averkiou, S. Maji, and S. Chaudhuri, “3d shape segmentation with projective convolutional networks,” Proc. CVPR, IEEE, vol. 2, 2017.[3] T. Funkhouser, M. Kazhdan, P. Shilane, P. Min, W. Kiefer, A. Tal, S. Rusinkiewicz, and D. Dobkin, “Modeling by example,” in ACM transactions on graphics (TOG), vol. 23, no. 3. ACM, 2004, pp. 652–663.[4] C. Lin, T. Fan, W. Wang, and M. Nießner, “Modeling 3d shapes by reinforcement learning,” arXiv preprint arXiv:2003.12397, 2020.[5] E. Zuckerberger, A. Tal, and S. Shlafman, “Polyhedral surface decomposition with applications,” Computers & Graphics, vol. 26, no. 5, pp. 733–743, 2002.[6] A. Ferreira, S. Marini, M. Attene, M. J. Fonseca, M. Spagnuolo, J. A. Jorge, and B. Falcidieno, “Thesaurus-based 3d object retrieval with part-in-whole matching,” International Journal of Computer Vision, vol. 89, no. 2-3, pp. 327–347, 2010.[7] A. Maglo, I. Grimstead, and C. Hudelot, “Cluster-based random accessible and progressive lossless compression of colored triangular meshes for interactive visualization,” in Proceedings of computer graphics international, 2011.[8] B. Lévy, S. Petitjean, N. Ray, and J. Maillot, “Least squares conformal maps for automatic texture atlas generation,” in ACM transactions on graphics (TOG), vol. 21, no. 3. ACM, 2002, pp. 362–371.[9] A. Agathos, I. Pratikakis, S. Perantonis, N. Sapidis, and P. Azariadis, “3d mesh segmentation methodologies for cad applications,” Computer-Aided Design and Applications, vol. 4, no. 6, pp. 827–841, 2007.[10] L. Shapira, A. Shamir, and D. Cohen-Or, “Consistent mesh partitioning and skeletonisation using the shape diameter function,” The Visual Computer, vol. 24, no. 4, p. 249, 2008.[11] Z. Shu, C. Qi, S. Xin, C. Hu, L. Wang, Y. Zhang, and L. Liu, “Unsupervised 3d shape segmentation and co-segmentation via deep learning,” Computer Aided Geometric Design, vol. 43, pp. 39– 52, 2016.[12] O. V. Kaick, N. Fish, Y. Kleiman, S. Asaﬁ, and D. Cohen-Or, “Shape segmentation by approximate convexity analysis,” ACM Transactions on Graphics (TOG), vol. 34, no. 1, p. 4, 2014.[13] A. Golovinskiy and T. Funkhouser, “Randomized cuts for 3d mesh analysis,” in ACM transactions on graphics (TOG), vol. 27, no. 5. ACM, 2008, p. 145.14[14] H. Blum, “A transformation for extracting new descriptors of shape,” Models for Perception of Speech and Visual Forms, 1967, pp. 362–380, 1967.[15] R. S. Rodrigues, J. F. Morgado, and A. J. Gomes, “Part-based mesh segmentation: A survey,” in Computer Graphics Forum, vol. 37, no. 6. Wiley Online Library, 2018, pp. 235–274.[16] E. Kalogerakis, A. Hertzmann, and K. Singh, “Learning 3d mesh segmentation and labeling,” in ACM Transactions on Graphics (TOG), vol. 29, no. 4. ACM, 2010, p. 102.[17] K. Guo, D. Zou, and X. Chen, “3d mesh labeling via deep convolutional neural networks,” ACM Transactions on Graphics (TOG), vol. 35, no. 1, p. 3, 2015.[18] H. Xu, M. Dong, and Z. Zhong, “Directionally convolutional networks for 3d shape segmentation,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2698–2707.[19] S. Asaﬁ, A. Goren, and D. Cohen-Or, “Weak convex decomposition by lines-of-sight,” in Computer graphics forum, vol. 32, no. 5. Wiley Online Library, 2013, pp. 23–31.[20] O. K.-C. Au, Y. Zheng, M. Chen, P. Xu, and C.-L. Tai, “Mesh segmentation with concavity-aware ﬁelds,” IEEE Transactions on Visualization and Computer Graphics, vol. 18, no. 7, pp. 1125–1134, 2012.[21] Y.-K. Lai, S.-M. Hu, R. R. Martin, and P. L. Rosin, “Fast mesh segmentation using random walks,” in Proceedings of the 2008 ACM symposium on Solid and physical modeling. ACM, 2008, pp. 183–191.[22] S. Katz, G. Leifman, and A. Tal, “Mesh segmentation using feature point and core extraction,” The Visual Computer, vol. 21, no. 8-10, pp. 649–658, 2005.[23] S. Shlafman, A. Tal, and S. Katz, “Metamorphosis of polyhedral surfaces using decomposition,” in Computer graphics forum, vol. 21, no. 3. Wiley Online Library, 2002, pp. 219–228.[24] X. Chen, A. Golovinskiy, and T. Funkhouser, “A benchmark for 3d mesh segmentation,” in Acm transactions on graphics (tog), vol. 28, no. 3. ACM, 2009, p. 73.[25] S. Tulsiani, H. Su, L. J. Guibas, A. A. Efros, and J. Malik, “Learning shape abstractions by assembling volumetric primitives,” in Computer Vision and Pattern Regognition (CVPR), 2017.[26] C.-Y. Sun, Q.-F. Zou, X. Tong, and Y. Liu, “Learning adaptive hierarchical cuboid abstractions of 3d shape collections,” ACM Transactions on Graphics (TOG), vol. 38, no. 6, p. 241, 2019.[27] R. Hu, L. Fan, and L. Liu, “Co-segmentation of 3d shapes via subspace clustering,” in Computer graphics forum, vol. 31, no. 5. Wiley Online Library, 2012, pp. 1703–1713.[28] Z. Wu, Y. Wang, R. Shou, B. Chen, and X. Liu, “Unsupervised co-segmentation of 3d shapes via afﬁnity aggregation spectral clustering,” Computers & Graphics, vol. 37, no. 6, pp. 628–637, 2013.[29] Z. Chen, K. Yin, M. Fisher, S. Chaudhuri, and H. Zhang, “Bae-net: Branched autoencoder for shape co-segmentation,” Proceedings of International Conference on Computer Vision (ICCV), 2019.[30] D. Brunner and G. Brunnett, “Mesh segmentation using the object skeleton graph,” in Proc. IASTED International Conf. on Computer Graphics and Imaging, 2004, pp. 48–55.[31] D. Reniers and A. Telea, “Part-type segmentation of articulated voxel-shapes using the junction rule,” in Computer Graphics Forum, vol. 27, no. 7. Wiley Online Library, 2008, pp. 1845–1852.[32] J. Tierny, J.-P. Vandeborre, and M. Daoudi, “Topology driven 3d mesh hierarchical segmentation,” in Shape Modeling and Applications, 2007. SMI’07. IEEE International Conference on. IEEE, 2007, pp. 215–220.[33] C. Feng, A. C. Jalba, and A. C. Telea, “Part-based segmentation by skeleton cut space analysis,” in International Symposium on Mathematical Morphology and Its Applications to Signal and Image Processing. Springer, 2015, pp. 607–618.[34] T. K. Dey and J. Sun, “Deﬁning and computing curve-skeletons with medial geodesic function,” in Symposium on geometry processing, vol. 6, 2006, pp. 143–152.[35] L. Lu, Y.-K. Choi, W. Wang, and M.-S. Kim, “Variational 3d shape segmentation for bounding volume computation,” in Computer Graphics Forum, vol. 26, no. 3. Wiley Online Library, 2007, pp. 329–338.[36] R. Liu, H. Zhang, A. Shamir, and D. Cohen-Or, “A part-aware surface metric for shape analysis,” in Computer Graphics Forum, vol. 28, no. 2. Wiley Online Library, 2009, pp. 397–406.[37] A. D. Kalvin and R. H. Taylor, “Superfaces: Polygonal mesh simpliﬁcation with bounded error,” IEEE Computer Graphics and Applications, vol. 16, no. 3, pp. 64–77, 1996.[38] B. Chazelle, D. P. Dobkin, N. Shouraboura, and A. Tal, “Strategies for polyhedral surface decomposition: an experimental study,” Computational Geometry, vol. 7, no. 5-6, pp. 327–342, 1997.[39] Y. Sun, D. L. Page, J. K. Paik, A. Koschan, and M. A. Abidi, “Triangle mesh-based edge detection and its application to surface segmentation and adaptive surface smoothing,” in Image Processing. 2002. Proceedings. 2002 International Conference on, vol. 3. IEEE, 2002, pp. 825–828.[40] A. Koschan, “Perception-based 3d triangle mesh segmentation using fast marching watersheds,” in Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on, vol. 2. IEEE, 2003, pp. II–II.[41] P. Li, B. Wang, F. Sun, X. Guo, C. Zhang, and W. Wang, “Q-mat: Computing medial axis transform by quadratic error minimization,” ACM Transactions on Graphics (TOG), vol. 35, no. 1, p. 8, 2015.[42] Y. Yan, D. Letscher, and T. Ju, “Voxel cores: Efﬁcient, robust, and provably good approximation of 3d medial axes,” ACM Transactions on Graphics (TOG), vol. 37, no. 4, p. 44, 2018.[43] D. Todorovic, “Gestalt principles,” Scholarpedia, vol. 3, no. 12, p. 5345, 2008.[44] R. Adams and L. Bischof, “Seeded region growing,” IEEE Transactions on pattern analysis and machine intelligence, vol. 16, no. 6, pp. 641–647, 1994.[45] Y. Rubner, C. Tomasi, and L. J. Guibas, “The earth mover’s distance as a metric for image retrieval,” International journal of computer vision, vol. 40, no. 2, pp. 99–121, 2000.[46] A. Delong, A. Osokin, H. N. Isack, and Y. Boykov, “Fast approximate energy minimization with label costs,” International journal of computer vision, vol. 96, no. 1, pp. 1–27, 2012.[47] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su et al., “Shapenet: An information-rich 3d model repository,” arXiv preprint arXiv:1512.03012, 2015.[48] J. Huang, H. Su, and L. Guibas, “Robust watertight manifold surface generation method for shapenet models,” arXiv preprint arXiv:1802.01698, 2018.[49] M. Attene, B. Falcidieno, and M. Spagnuolo, “Hierarchical mesh segmentation based on ﬁtting primitives,” The Visual Computer, vol. 22, no. 3, pp. 181–193, 2006.[50] Y. Zhou, K. Yin, H. Huang, H. Zhang, M. Gong, and D. Cohen-Or, “Generalized cylinder decomposition.” ACM Trans. Graph., vol. 34, no. 6, pp. 171–1, 2015.[51] C. Zhu, K. Xu, S. Chaudhuri, R. Yi, and H. Zhang, “Scores: Shape composition with recursive substructure priors,” ACM Transactions on Graphics (SIGGRAPH Asia 2018), vol. 37, no. 6, p. Article 211, 2018.[52] S. Har-Peled, “A practical approach for computing the diameter of a point set,” in Proceedings of the seventeenth annual symposium on Computational geometry. ACM, 2001, pp. 177–186.[53] S. Wu, H. Huang, M. Gong, M. Zwicker, and D. Cohen-Or, “Deep points consolidation,” ACM Transactions on Graphics (ToG), vol. 34, no. 6, p. 176, 2015.[54] Y. Yan, K. Sykes, E. Chambers, D. Letscher, and T. Ju, “Erosion thickness on medial axes of 3d shapes,” ACM Transactions on Graphics (TOG), vol. 35, no. 4, p. 38, 2016.